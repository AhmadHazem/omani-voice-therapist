{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301b86b2",
   "metadata": {},
   "source": [
    "# Omani-Voice-Therapist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac6f048",
   "metadata": {},
   "source": [
    "## Tools Intailization, Libraries importing, LLMs assignmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f886e2e",
   "metadata": {},
   "source": [
    "### General Intializations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb75cae",
   "metadata": {},
   "source": [
    "#### Libraries Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7393eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, AnyMessage\n",
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory, BaseChatMessageHistory\n",
    "from openai import OpenAI\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import logging\n",
    "import io\n",
    "import uuid\n",
    "import soundfile as sf\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcdec06",
   "metadata": {},
   "source": [
    "##### Intializing LLMs and Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3970f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intializng OpenAI\n",
    "openai_model = \"gpt-4o\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "GPT4o = ChatOpenAI(temperature = 0, model= openai_model, streaming = True).configurable_fields(\n",
    "    callbacks=ConfigurableField(\n",
    "        id=\"callbacks\",\n",
    "        name=\"callbacks\",\n",
    "        description=\"A list of callbacks to use for streaming\",\n",
    "    )\n",
    ")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "## Intailzing Claude\n",
    "claude_model = \"claude-3-7-sonnet-latest\"\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "ClaudeSonnet3_7 = ChatAnthropic(temperature= 0, model_name= claude_model, streaming= True).configurable_fields(\n",
    "    callbacks=ConfigurableField(\n",
    "        id=\"callbacks\",\n",
    "        name=\"callbacks\",\n",
    "        description=\"A list of callbacks to use for streaming\",\n",
    "    )\n",
    ")\n",
    "\n",
    "## Intailzing Langchain \n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"omani-therapist-voice\"\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "## Azure Speech Services API Key\n",
    "SPEECH_KEY =  os.getenv(\"SPEECH_KEY\")\n",
    "SPEECH_ENDPOINT = os.getenv(\"ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05175b76",
   "metadata": {},
   "source": [
    "#### Logger Intialization and Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3b65fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧭 Logger Setup\n",
    "def setup_logging():\n",
    "    \"\"\"Configure logging for the application\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "        handlers=[logging.StreamHandler()]\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "logger = setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af690e",
   "metadata": {},
   "source": [
    "## Agent Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ede6a",
   "metadata": {},
   "source": [
    "##### General Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2d6a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_search = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    ")\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "# Define the multiply tool\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "# Define the exponentiate tool\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x\n",
    "\n",
    "def Notify(email):\n",
    "    \"\"\"Notify Authorities if patient emotional Health is in critical conditions or he/she are mentioning about harming themselves or others\"\"\"\n",
    "    return \"Notified Police and Called an Ambulance, and \" + email\n",
    "\n",
    "@tool\n",
    "def health_searcher(query : str):\n",
    "    \"\"\"Use this function strictly when the user asks for you to search about mental health therapy techniques, nearest mental hospitals, \n",
    "    mental health medications in Oman, hotlines and nothing else\"\"\"\n",
    "    return tavily_search.invoke(query)\n",
    "\n",
    "@tool\n",
    "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
    "    \"\"\"Use this tool to provide a final answer to the user.\n",
    "    The answer should be in natural language as this will be provided\n",
    "    to the user directly. The tools_used must include a list of tool\n",
    "    names that were used within the `scratchpad`.\n",
    "    \"\"\"\n",
    "    return {\"answer\": answer, \"tools_used\": tools_used}\n",
    "\n",
    "tools = [add, multiply, exponentiate, subtract, final_answer, health_searcher]\n",
    "name2tool = {tool.name : tool.func for tool in tools}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced1ca1",
   "metadata": {},
   "source": [
    "##### Adjusting System Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1afdd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_RISK_ANALYZER = \\\n",
    "(\n",
    "    \"You are an Omani AI Therapist, and you're task is to provide solutions for the users emotional issues. \\n\"\n",
    "    \"Also, You're task is to analyze the user's prompt emotion/feeling.\\n\"\n",
    "    \"You will try to provide solutions for users and help them using Cogonitive Behaviour Techniques (CBT), if it is possible, otherwise put None.\\n\"\n",
    "    \"You will mention the reason behind your selection for this, and how to apply it .\\n\"\n",
    "    \"You will try to include, if posssible, omani and islamic values for the cultural context for how to solve this problem.\\n\"\n",
    "    \"You will fill 8 variables: requires_analysis, user_emotion, severity, diagnosis, user_prompt, cbt_technique, reason_for_technique, cultural_context \\n\"\n",
    "    \"If you did not manage to fill any of those variables just put None, and do not add anything else\"\n",
    "    \"You will reply in arabic and be brief as possible\"\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT_THERAPIST = \\\n",
    "(\n",
    "    \"You are an Omani AI Therapist, and you will recieve a structured enhanced prompt of patients.\\n\"\n",
    "    \"Your task is reply back to the user in authentic omani arabic\"\n",
    "    \"If user's problem is not mentioned, you can encourge him/her to give more details about his/her problem\"\n",
    "    \"You must adhere to omani gulf culture, and Islamic context, and not mention anything that contradicts with those values\"\n",
    "    \"You can use Islamic versus if it is needed but do not over use it\"\n",
    "    \"If variable required_analysis is False, reply back normally to the user without usage of the variables you will recieve about him/her\"\n",
    "    \"You must use the following summary dowm below about the user and adapot your response to it\"\n",
    "    \"Patient Summary :\\n\" \\\n",
    "    \"requires_analysis: {requires_analysis}\\n\"\n",
    "    \"user_emotion: {user_emotion}\\n\"\n",
    "    \"severity:{severity}\\n\"\n",
    "    \"diagnosis:{diagnosis}\\n\"\n",
    "    \"cbt_technique:{cbt_technique}\\n\"\n",
    "    \"reason_for_technique:{reason_for_technique}\\n\"\n",
    "    \"cultural_context:{cultural_context}\\n\"\n",
    "    \"Mention the CBT Technique needed, and provide life examples for how to apply it, why it will work.\"\n",
    "    \"(user_prompt:{user_prompt}) only to the tool as args\"\n",
    "    \"Use Notify tool if the user exhibits any critically concerning prompt like harming himself or others\"\n",
    "    \"You MUST then use the final_answer tool to provide a final answer to the user. \"\n",
    "    \"DO NOT use the same tool more than once.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207703ce",
   "metadata": {},
   "source": [
    "##### Modified Human's prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8452d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMAN_PROMPT_RISK_ANALYZER = \\\n",
    "(\n",
    "    \"{patient_prompt}\"\n",
    ")\n",
    "\n",
    "HUMAN_PROMPT_ENHANCED = \\\n",
    "(\n",
    "    \"This is the user's prompt : {user_prompt}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c614f24",
   "metadata": {},
   "source": [
    "##### Adjusting the Chat's templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23df4ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt_Template_Step_One = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",  SYSTEM_PROMPT_RISK_ANALYZER),\n",
    "    (\"user\", HUMAN_PROMPT_RISK_ANALYZER)\n",
    "])\n",
    "\n",
    "Prompt_Template_Step_Two = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYSTEM_PROMPT_THERAPIST),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", HUMAN_PROMPT_ENHANCED)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6687d376",
   "metadata": {},
   "source": [
    "##### Creating Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77c54c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output For Step 1\n",
    "class StructuredRiskAssessorTemplate(BaseModel):\n",
    "    requires_analysis: bool = Field(description= \"This varaible will contain whether the user's prompt requires analysis if he/she is in\" \\\n",
    "                                                \" emotional pain. It will be true if user is in emotional pain, and false if it is a\" \\\n",
    "                                                \"normal prompt or not emotional pain is detected\")\n",
    "    user_emotion: str = Field(description=\n",
    "                                    \"This is a variable, where will you fill it with your predication about the user's \" \\\n",
    "                                    \"emotion based on his/her prompt.\")\n",
    "    severity: str = Field(description=\n",
    "                                    \"This is a variable, where will you fill it with you predication about the severity\" \\\n",
    "                                    \"of the emotion - it should be eith LOW/MED/HIGH/CRIT.\")\n",
    "    diagnosis: str = Field(description= \n",
    "                                    \"This variable will contain the diagnosis behind this user's emotion. \" \\\n",
    "                                    \"It has to be a Hierarchical Diagnosis something similar to those examples but not explicitly from it: \" \\\n",
    "                                    \"الحالات النفسية السلوكية - مشاكل النوم - أحلام اليقظة\" \\\n",
    "                                    \"الأمراض الذهانية - مشاكل الفصام والذهان - الفصام\" \\\n",
    "                                    \"الأمراض المزاجية - الاكتئاب - الاكتئاب الحاد\" \\\n",
    "                                    \"الأمراض القلقية - القلق العام - اضطراب الهلع\" \\\n",
    "                                    \"الأمراض النفسية الأخرى - الوسواس القهري - اضطراب ما بعد الصدمة\" \\\n",
    "                                    \"الأمراض السلوكية - الإدمان - إدمان المخدرات\" \\\n",
    "                                    \"الأمراض النفسية للأطفال والمراهقين - مشاكل النمو - اضطرابات السلوك\" \\\n",
    "                                    \"الأمراض النفسية لدى كبار السن - الخرف - الاضطرابات المعرفية\" \\\n",
    "    \n",
    "                                    \"If not mentioned, then state that it is non mentioned.\"\n",
    "                                    \"\")\n",
    "    user_prompt: str = Field(description= \n",
    "                                    \"This variable will contain the user's original prompt, \" \\\n",
    "                                    \"so just copy it as it is and put in that variable.\")\n",
    "    cbt_technique: str = Field(description=\"This variable will contain the suggested (CBT) to help the user\")\n",
    "    reason_for_technique: str = Field(description= \"This varaible will contain the reason behind picking that CBT, and how can it help\")\n",
    "    cultural_context: str = Field(description=\"This variable will contain how can Omani and Islamic values can help the user in his emotional problem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19983500",
   "metadata": {},
   "source": [
    "##### Agents Chat History Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0f2666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    \"\"\"In memory implementation of chat message history.\"\"\"\n",
    "\n",
    "    messages: list[BaseMessage] = Field(default_factory=list)\n",
    "\n",
    "    def add_messages(self, messages: list[BaseMessage]) -> None:\n",
    "        \"\"\"Add a list of messages to the store\"\"\"\n",
    "        self.messages.extend(messages)\n",
    "\n",
    "    def format_messages(self) -> None:\n",
    "        for i in range(len(self.messages)):\n",
    "            if (isinstance(self.messages[i], ToolMessage)):\n",
    "                start = max(0, i - 2)\n",
    "                end = i + 1\n",
    "                self.messages = self.messages[:start] + self.messages[end:]\n",
    "                return\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "\n",
    "chat_map = {}\n",
    "def get_chat_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in chat_map:\n",
    "        # if session ID doesn't exist, create a new chat history\n",
    "        chat_map[session_id] = InMemoryHistory()\n",
    "    return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d187d",
   "metadata": {},
   "source": [
    "##### Agents Intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53b7effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from langchain.callbacks.base import AsyncCallbackHandler\n",
    "\n",
    "\n",
    "class QueueCallbackHandler(AsyncCallbackHandler):\n",
    "    \"\"\"Callback handler that puts tokens into a queue.\"\"\"\n",
    "\n",
    "    def __init__(self, queue: asyncio.Queue):\n",
    "        self.queue = queue\n",
    "        self.final_answer_seen = False\n",
    "\n",
    "    async def __aiter__(self):\n",
    "        while True:\n",
    "            if self.queue.empty():\n",
    "                await asyncio.sleep(0.1)\n",
    "                continue\n",
    "            token_or_done = await self.queue.get()\n",
    "\n",
    "            if token_or_done == \"<<DONE>>\":\n",
    "                # this means we're done\n",
    "                return\n",
    "            if token_or_done:\n",
    "                yield token_or_done\n",
    "\n",
    "    async def on_llm_new_token(self, *args, **kwargs) -> None:\n",
    "        \"\"\"Put new token in the queue.\"\"\"\n",
    "        #print(f\"on_llm_new_token: {args}, {kwargs}\")\n",
    "        chunk = kwargs.get(\"chunk\")\n",
    "        if chunk:\n",
    "            # check for final_answer tool call\n",
    "            if tool_calls := chunk.message.additional_kwargs.get(\"tool_calls\"):\n",
    "                if tool_calls[0][\"function\"][\"name\"] == \"final_answer\":\n",
    "                    # this will allow the stream to end on the next `on_llm_end` call\n",
    "                    self.final_answer_seen = True\n",
    "        self.queue.put_nowait(kwargs.get(\"chunk\"))\n",
    "        return\n",
    "\n",
    "    async def on_llm_end(self, *args, **kwargs) -> None:\n",
    "        \"\"\"Put None in the queue to signal completion.\"\"\"\n",
    "        #print(f\"on_llm_end: {args}, {kwargs}\")\n",
    "        # this should only be used at the end of our agent execution, however LangChain\n",
    "        # will call this at the end of every tool call, not just the final tool call\n",
    "        # so we must only send the \"done\" signal if we have already seen the final_answer\n",
    "        # tool call\n",
    "        if self.final_answer_seen:\n",
    "            self.queue.put_nowait(\"<<DONE>>\")\n",
    "        else:\n",
    "            self.queue.put_nowait(\"<<STEP_END>>\")\n",
    "        return\n",
    "    \n",
    "\n",
    "queue = asyncio.Queue()\n",
    "streamer = QueueCallbackHandler(queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66cc514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Therpaist:\n",
    "    chat_history: list[BaseMessage]\n",
    "\n",
    "    def __init__(self, model, max_iterations = 3):\n",
    "        self.chat_history = []\n",
    "        self.model = model\n",
    "        self.max_iterations = max_iterations\n",
    "        self.model_riskAnalyzer = model.with_structured_output(StructuredRiskAssessorTemplate)\n",
    "        self.chain_one: RunnableSerializable = \\\n",
    "        (\n",
    "            Prompt_Template_Step_One |\n",
    "            self.model_riskAnalyzer |\n",
    "            {\n",
    "                \"requires_analysis\": lambda x: x.requires_analysis,\n",
    "                \"user_emotion\": lambda x: x.user_emotion,\n",
    "                \"severity\": lambda x: x.severity,\n",
    "                \"diagnosis\": lambda x:x.diagnosis,\n",
    "                \"user_prompt\": lambda x:x.user_prompt,\n",
    "                \"cbt_technique\": lambda x:x.cbt_technique,\n",
    "                \"reason_for_technique\" : lambda x:x.reason_for_technique,\n",
    "                \"cultural_context\": lambda x:x.cultural_context\n",
    "            } \n",
    "        )\n",
    "\n",
    "\n",
    "        self.chain_two : RunnableSerializable = \\\n",
    "        (\n",
    "            {\n",
    "                \"requires_analysis\": lambda x: x['requires_analysis'],\n",
    "                \"user_emotion\": lambda x: x['user_emotion'],\n",
    "                \"severity\": lambda x: x['severity'],\n",
    "                \"diagnosis\": lambda x:x['diagnosis'],\n",
    "                \"user_prompt\": lambda x:x['user_prompt'],\n",
    "                \"cbt_technique\": lambda x:x['cbt_technique'],\n",
    "                \"reason_for_technique\" : lambda x:x['reason_for_technique'],\n",
    "                \"cultural_context\": lambda x:x['cultural_context'],\n",
    "                \"chat_history\": lambda x:x.get('chat_history', []),\n",
    "                \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "            } |\n",
    "            Prompt_Template_Step_Two |\n",
    "            self.model.bind_tools(tools, tool_choice=\"any\")\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.agent = RunnableWithMessageHistory (\n",
    "            runnable= self.chain_two,\n",
    "            get_session_history= get_chat_history,\n",
    "            input_messages_key=\"user_prompt\",\n",
    "            history_messages_key=\"chat_history\"\n",
    "        ) \n",
    "\n",
    "\n",
    "    async def invoke_step1(self, input: str) -> dict:\n",
    "        logging.info(f\"Chain One Started, and {self.model} recieved User Input...\")\n",
    "        return await self.chain_one.ainvoke({\"patient_prompt\": input})\n",
    "    \n",
    "\n",
    "    async def invoke_step2(self, input:dict , session_id:str, verbose:bool = False):\n",
    "        # invoke the agent but we do this iteratively in a loop until\n",
    "        # reaching a final answer\n",
    "        count = 0\n",
    "        agent_scratchpad = []\n",
    "        while count < self.max_iterations:\n",
    "            # invoke a step for the agent to generate a tool call\n",
    "            async def stream(query: dict):\n",
    "                response = self.agent.with_config(\n",
    "                    callbacks=[streamer]\n",
    "                )\n",
    "                # we initialize the output dictionary that we will be populating with\n",
    "                # our streamed output\n",
    "                output = None\n",
    "                # now we begin streaming\n",
    "                input = query \n",
    "                async for token in response.astream(input = input , config= {\"session_id\" : session_id}):\n",
    "                    if output is None:\n",
    "                        output = token\n",
    "                    else:\n",
    "                        # we can just add the tokens together as they are streamed and\n",
    "                        # we'll have the full response object at the end\n",
    "                        output += token\n",
    "                    if token.content != \"\":\n",
    "                        # we can capture various parts of the response object\n",
    "                        if verbose: print(f\"content: {token.content}\", flush=True)\n",
    "                    tool_calls = token.additional_kwargs.get(\"tool_calls\")\n",
    "                    if tool_calls:\n",
    "                        if verbose: print(f\"tool_calls: {tool_calls}\", flush=True)\n",
    "                        tool_name = tool_calls[0][\"function\"][\"name\"]\n",
    "                        if tool_name:\n",
    "                            if verbose: print(f\"tool_name: {tool_name}\", flush=True)\n",
    "                        arg = tool_calls[0][\"function\"][\"arguments\"]\n",
    "                        if arg != \"\":\n",
    "                            if verbose: print(f\"arg: {arg}\", flush=True)\n",
    "                if output.tool_calls and len(output.tool_calls) > 0:\n",
    "                    return AIMessage(\n",
    "                        content=output.content,\n",
    "                        tool_calls=output.tool_calls,\n",
    "                        tool_call_id=output.tool_calls[0][\"id\"]\n",
    "                    )\n",
    "                else:\n",
    "                    return AIMessage(content=output.content)\n",
    "\n",
    "\n",
    "            tool_call = await stream(query=input)\n",
    "            # add initial tool call to scratchpad\n",
    "            #agent_scratchpad.append(tool_call)\n",
    "            # otherwise we execute the tool and add it's output to the agent scratchpad\n",
    "            tool_name = tool_call.tool_calls[0][\"name\"]\n",
    "            tool_args = tool_call.tool_calls[0][\"args\"]\n",
    "            tool_call_id = tool_call.tool_call_id\n",
    "            tool_out = name2tool[tool_name](**tool_args)\n",
    "            # add the tool output to the agent scratchpad\n",
    "            tool_exec = ToolMessage(\n",
    "                content=f\"{tool_out}\",\n",
    "                tool_call_id=tool_call_id\n",
    "            )\n",
    "            #agent_scratchpad.append(tool_exec)\n",
    "            chat_map[session_id].add_messages([tool_exec])\n",
    "            count += 1\n",
    "            # if the tool call is the final answer tool, we stop\n",
    "            if tool_name == \"final_answer\":\n",
    "                break\n",
    "        # add the final output to the chat history, we only add the \"answer\" field\n",
    "        final_answer = tool_out[\"answer\"]\n",
    "        chat_map[session_id].add_messages([\n",
    "            HumanMessage(content=input['user_prompt']),\n",
    "            AIMessage(content=final_answer)\n",
    "        ])\n",
    "\n",
    "\n",
    "        chat_map[session_id].format_messages()\n",
    "        return final_answer\n",
    "\n",
    "\n",
    "    def invoke(self, input: str, session_id:str):\n",
    "        analysis = self.chain_one.invoke({\n",
    "            \"patient_prompt\": input\n",
    "        })   \n",
    "\n",
    "        \n",
    "        out = self.agent.invoke(analysis, config={\"session_id\" : session_id})\n",
    "        return out\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e8f943",
   "metadata": {},
   "source": [
    "### Azure TTS Omani Voice Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4504bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Speaker:\n",
    "\n",
    "    def __init__(self):\n",
    "        speech_config = speechsdk.SpeechConfig(subscription= SPEECH_KEY ,endpoint= SPEECH_ENDPOINT)\n",
    "        speech_config.speech_synthesis_voice_name = \"ar-OM-AbdullahNeural\"\n",
    "        self.synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n",
    "    \n",
    "    def speak(self, text: str):\n",
    "        \"\"\"Synthesize and play text\"\"\"\n",
    "        try:\n",
    "            logger.info(\"🔊 Speaking with Azure TTS...\")\n",
    "            result = self.synthesizer.speak_text_async(text).get()\n",
    "            \n",
    "            if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "                logger.info(\"✅ Speech synthesized.\")\n",
    "                return result.audio_data\n",
    "            else:\n",
    "                logger.warning(f\"❌ Speech synthesis failed: {result.reason}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Speaker Error: {e}\")\n",
    "            return None\n",
    "\n",
    "# speaker = Speaker()\n",
    "# speaker.speak(\"السلام عليكم ورحمه الله و بركاته\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f330f644",
   "metadata": {},
   "source": [
    "### Whisper-1 Voice Transcriber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a319f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhisperTranscriber:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "    def TranscribeStream(self, audio_tuple) -> str:\n",
    "\n",
    "        sample_rate, audio_np = audio_tuple\n",
    "\n",
    "        # Convert NumPy array to WAV in-memory\n",
    "        buffer = io.BytesIO()\n",
    "        sf.write(buffer, audio_np, samplerate=sample_rate, format='WAV')\n",
    "        buffer.seek(0)\n",
    "\n",
    "        # Wrap the buffer with filename and MIME type\n",
    "        buffer.name = \"audio.wav\"  # Important for format recognition\n",
    "\n",
    "        try:\n",
    "            transcript = self.client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=buffer,\n",
    "                prompt= \"You may recieve some english word with the arabic speech, \"\n",
    "                \"and you will have to transcribe them as they are. Do not transcribe an English word into arabic. \",\n",
    "                language=\"ar\",\n",
    "                response_format=\"text\",\n",
    "                timeout=10\n",
    "            )\n",
    "\n",
    "            buffer.close()  # Close the buffer after use\n",
    "            return transcript\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"⚠️ Whisper transcription failed: {e}\")\n",
    "            return \"فشل في التسجيل\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b79c0fe",
   "metadata": {},
   "source": [
    "## Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5068b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_response(gpt_analysis : dict, claude_analysis : dict) -> float:\n",
    "    model_comparer = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    similarity_scores = []\n",
    "    logging.info(f\"GPT Therapist analysis:{gpt_analysis}\")\n",
    "    logging.info(f\"Claude Therapist analysis: {claude_analysis}\")\n",
    "    for key in gpt_analysis.keys():\n",
    "        embeddings = model_comparer.encode([str(gpt_analysis[key]), str(claude_analysis[key])], show_progress_bar= False)\n",
    "        similarity_scores.append(util.cos_sim(embeddings[0], embeddings[1]))\n",
    "    similarity_score = float(np.average(similarity_scores))\n",
    "    return np.average(similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e54f3",
   "metadata": {},
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3278f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "therapist_GPT = Therpaist(GPT4o)\n",
    "therapist_claude = Therpaist(ClaudeSonnet3_7)\n",
    "\n",
    "async def therapist_chat(prompt: str, timeout: float = 10.0, max_retries: int = 3, session_id: str = \"abc123\", emergency_contacts=[]):\n",
    "    try:\n",
    "        retries = 1\n",
    "        final_analysis = None\n",
    "\n",
    "        logger.info(\"Phase 1: Sending Prompt to the AI Therapists......\")\n",
    "        gpt_task = asyncio.create_task(therapist_GPT.invoke_step1(prompt))\n",
    "        claude_task = asyncio.create_task(therapist_claude.invoke_step1(prompt))\n",
    "\n",
    "        # Wait up to timeout for both tasks to complete\n",
    "        done, pending = await asyncio.wait(\n",
    "            [gpt_task, claude_task],\n",
    "            timeout=timeout,\n",
    "            return_when=asyncio.ALL_COMPLETED\n",
    "        )\n",
    "\n",
    "        if len(done) == 2:\n",
    "            logger.info(\"Phase 1: Analysis Finished For Both Therapists\")\n",
    "            gpt_result = await gpt_task\n",
    "            claude_result = await claude_task\n",
    "            score = validate_response(gpt_result, claude_result)\n",
    "            logging.info(f\"Similarity Score is : {score}\")\n",
    "            if score > 0.5 or (not gpt_result['requires_analysis'] and not claude_result['requires_analysis']) or retries == max_retries:\n",
    "                final_analysis = gpt_result\n",
    "            else:\n",
    "                retries += 1\n",
    "\n",
    "        elif gpt_task in done:\n",
    "            logger.info(\"Phase 1: Analysis Finished For Only GPT\")\n",
    "            for task in pending:\n",
    "                task.cancel()\n",
    "            final_analysis = await gpt_task\n",
    "\n",
    "        elif claude_task in done:\n",
    "            logger.info(\"Phase 1: Analysis Finished For Only Claude\")\n",
    "            for task in pending:\n",
    "                task.cancel()\n",
    "            final_analysis = await claude_task\n",
    "\n",
    "        logger.info(\"Phase 2: Adapting the response\")\n",
    "        if final_analysis['severity'] == \"CRIT\":\n",
    "            logging.info(\"User Prompt situation is critical; Notifying Authorities .......\")\n",
    "            Notify(emergency_contacts)\n",
    "\n",
    "        tokens = await therapist_GPT.invoke_step2(final_analysis, session_id=session_id)\n",
    "        for token in tokens:\n",
    "            yield token\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "        yield \"عفوا لقد حدث خطأ حاول من جديد\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a622c2f",
   "metadata": {},
   "source": [
    "### Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92cb743f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_23944\\2468267645.py:92: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot()\n",
      "2025-08-14 16:55:54,083 | INFO | HTTP Request: GET http://127.0.0.1:7861/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-08-14 16:55:54,096 | INFO | HTTP Request: HEAD http://127.0.0.1:7861/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:55:55,280 | INFO | HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import uuid\n",
    "import asyncio\n",
    "import gradio as gr\n",
    "\n",
    "speaker = Speaker()\n",
    "transcriber = WhisperTranscriber()\n",
    "\n",
    "class AppState:\n",
    "    stream: np.ndarray | None = None\n",
    "    session_id: str = str(uuid.uuid4()).replace('-', '')[:10]\n",
    "    sampling_rate: int = 0\n",
    "    conversation: list = []\n",
    "    emergency_contacts: list = []\n",
    "\n",
    "def add_contact(new_contact, state):\n",
    "    if new_contact.strip():\n",
    "        state.emergency_contacts.append(new_contact.strip())\n",
    "    return '\\n'.join(state.emergency_contacts), state\n",
    "\n",
    "def delete_contacts(state):\n",
    "    state.emergency_contacts = []\n",
    "    return None, state\n",
    "\n",
    "def estimate_audio_duration(audio_bytes: bytes, sampling_rate: int = 16000) -> float:\n",
    "    # Assuming 16-bit mono PCM: 2 bytes per sample\n",
    "    byte_count = len(audio_bytes)\n",
    "    return byte_count / (sampling_rate * 2)\n",
    "\n",
    "def clear_conversation(state):\n",
    "    state.conversation = []\n",
    "    state.stream = None\n",
    "    chat_map[state.session_id].clear()\n",
    "    return None, state.conversation, state\n",
    "\n",
    "def process_audio(audio, state):\n",
    "    sr, chunk = audio\n",
    "    if state.stream is None:\n",
    "        state.stream = chunk\n",
    "        state.sampling_rate = sr\n",
    "    else:\n",
    "        state.stream = np.concatenate((state.stream, chunk))\n",
    "    return None, state  # Just update the stream\n",
    "\n",
    "# 🔊 Run blocking speaker.speak() in async thread\n",
    "async def speak_chunk(text):\n",
    "    return await asyncio.to_thread(speaker.speak, text)\n",
    "\n",
    "# 🚀 Response loop with async streaming playback\n",
    "async def response(audio, state):\n",
    "    if state.stream is None or len(state.stream) == 0:\n",
    "        yield None, state, state.conversation\n",
    "\n",
    "    user_prompt = transcriber.TranscribeStream((state.sampling_rate, state.stream))\n",
    "    state.conversation.append([user_prompt, \".....\"])\n",
    "    yield None, state, state.conversation\n",
    "\n",
    "    state.conversation[-1][1] = \"\"  # Clear placeholder\n",
    "\n",
    "    buffer = \"\"\n",
    "    buffer_threshold = 1000  # Batching threshold\n",
    "    reply = \"\"\n",
    "\n",
    "    async for token in therapist_chat(user_prompt, timeout=12, session_id= \"abc123\", emergency_contacts= state.emergency_contacts):\n",
    "        buffer += token\n",
    "        state.conversation[-1][1] += token  # Update chatbot text live\n",
    "\n",
    "        if len(buffer) > buffer_threshold or buffer.endswith((\".\", \"!\", \"?\", \"،\",'\\n')):\n",
    "            reply += buffer\n",
    "            audio_chunk = await speak_chunk(buffer)\n",
    "            buffer = \"\"\n",
    "            yield audio_chunk, state, state.conversation\n",
    "            duration = estimate_audio_duration(audio_chunk, state.sampling_rate)\n",
    "            await asyncio.sleep(duration * 2.5)  # Slightly less for smoother UX\n",
    "\n",
    "\n",
    "    # Catch leftover buffer\n",
    "    if buffer:\n",
    "        reply += buffer\n",
    "        audio_chunk = await speak_chunk(buffer)\n",
    "        state.conversation[-1][1] += buffer\n",
    "        yield audio_chunk, state, state.conversation\n",
    "\n",
    "    state.stream = None  # Reset stream for next round\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    state = gr.State(AppState())\n",
    "    input_audio = gr.Audio(type=\"numpy\", streaming=True, label=\"Record your voice\")\n",
    "    output_audio = gr.Audio(label=\"AI Response\", autoplay=True)\n",
    "    chatbot = gr.Chatbot()\n",
    "    clear_btn = gr.Button(\"🔄 Clear Conversation\")\n",
    "    gr.Markdown(\"### 🆘 Emergency Contacts\")\n",
    "    with gr.Row():\n",
    "        contact_input = gr.Textbox(placeholder=\"Enter emergency contact (e.g., name & number)\", label=\"Add Contact\")\n",
    "        add_btn = gr.Button(\"➕ Add Contact\")\n",
    "        delete_btn = gr.Button(\"Clear Contacts\")\n",
    "    contacts_display = gr.Textbox(label=\"Saved Contacts\", interactive=False)\n",
    "\n",
    "    add_btn.click(fn=add_contact, inputs=[contact_input, state], outputs=[contacts_display, state])\n",
    "    delete_btn.click(fn=delete_contacts, inputs = [state], outputs= [contacts_display, state])\n",
    "    input_audio.stream(process_audio, [input_audio, state], [input_audio, state], stream_every = 0.5, queue=False)\n",
    "    input_audio.stop_recording(response, [input_audio,state], [output_audio, state, chatbot])\n",
    "    clear_btn.click(fn=clear_conversation, inputs=[state], outputs=[output_audio, chatbot, state])\n",
    "\n",
    "demo.launch()\n",
    "# app = gr.mount_gradio_app(app, demo, path=\"/gradio\")\n",
    "\n",
    "# # Redirect root '/' to '/gradio'\n",
    "# @app.get(\"/\")\n",
    "# def redirect_to_gradio():\n",
    "#     return RedirectResponse(url=\"/gradio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b44d93bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'abc123'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mchat_map\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mabc123\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.clear()\n",
      "\u001b[31mKeyError\u001b[39m: 'abc123'"
     ]
    }
   ],
   "source": [
    "chat_map['abc123'].clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf1373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='السلام عليكم ورحمة الله وبركاته. انا اسمي احمد حازم. انا عندي قلق شديد من المستقبل.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='وعليكم السلام ورحمة الله وبركاته، أخي أحمد. القلق من المستقبل أمر شائع، ولكن من المهم أن نحاول التعامل معه بطريقة صحية. في الثقافة العمانية والإسلامية، يمكننا الاعتماد على الإيمان بالله والتوكل عليه، حيث أن الله هو المدبر لكل شيء. \\n\\nيمكنك استخدام تقنية إعادة الهيكلة المعرفية، وهي جزء من العلاج السلوكي المعرفي (CBT)، لتحدي الأفكار السلبية والمخاوف غير الواقعية عن المستقبل. حاول أن تكتب مخاوفك وتفكر في مدى واقعيتها، ثم استبدلها بأفكار أكثر إيجابية وواقعية. \\n\\nتذكر قول الله تعالى: \"وَمَن يَتَوَكَّلْ عَلَى اللَّهِ فَهُوَ حَسْبُهُ\". هذا يمكن أن يكون مصدر طمأنينة لك. إذا كنت بحاجة إلى مزيد من الدعم، لا تتردد في التواصل مع مختص نفسي.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='هل يمكنك أن تعطيني أرقام هواتف مستشفيات التي تختص في علاج الأمراض النفسية في مصقط؟', additional_kwargs={}, response_metadata={}),\n",
       " AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Y0HqQ3ItnpMjJFG4xDXjrIee', 'function': {'arguments': '{\"answer\":\"بالطبع، هنا بعض أرقام الهواتف لمستشفيات ومراكز علاج الأمراض النفسية في مسقط:\\\\n\\\\n1. مركز القمة للإستشارات النفسية - مسقط: 24511010\\\\n2. مستشفى المسرة: +968 24 873000\\\\n3. دكتور نفسي في مسقط: 99019648\\\\n\\\\nيمكنك التواصل مع هذه المراكز للحصول على المساعدة التي تحتاجها. أتمنى لك الصحة والعافية.\",\"tools_used\":[\"functions.health_searcher\"]}', 'name': 'final_answer'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ff25b2783a', 'service_tier': 'default'}, id='run--164f85a8-c2f6-4860-b3ad-8ca75f27afcd', tool_calls=[{'name': 'final_answer', 'args': {'answer': 'بالطبع، هنا بعض أرقام الهواتف لمستشفيات ومراكز علاج الأمراض النفسية في مسقط:\\n\\n1. مركز القمة للإستشارات النفسية - مسقط: 24511010\\n2. مستشفى المسرة: +968 24 873000\\n3. دكتور نفسي في مسقط: 99019648\\n\\nيمكنك التواصل مع هذه المراكز للحصول على المساعدة التي تحتاجها. أتمنى لك الصحة والعافية.', 'tools_used': ['functions.health_searcher']}, 'id': 'call_Y0HqQ3ItnpMjJFG4xDXjrIee', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'final_answer', 'args': '{\"answer\":\"بالطبع، هنا بعض أرقام الهواتف لمستشفيات ومراكز علاج الأمراض النفسية في مسقط:\\\\n\\\\n1. مركز القمة للإستشارات النفسية - مسقط: 24511010\\\\n2. مستشفى المسرة: +968 24 873000\\\\n3. دكتور نفسي في مسقط: 99019648\\\\n\\\\nيمكنك التواصل مع هذه المراكز للحصول على المساعدة التي تحتاجها. أتمنى لك الصحة والعافية.\",\"tools_used\":[\"functions.health_searcher\"]}', 'id': 'call_Y0HqQ3ItnpMjJFG4xDXjrIee', 'index': 0, 'type': 'tool_call_chunk'}]),\n",
       " ToolMessage(content=\"{'answer': 'بالطبع، هنا بعض أرقام الهواتف لمستشفيات ومراكز علاج الأمراض النفسية في مسقط:\\\\n\\\\n1. مركز القمة للإستشارات النفسية - مسقط: 24511010\\\\n2. مستشفى المسرة: +968 24 873000\\\\n3. دكتور نفسي في مسقط: 99019648\\\\n\\\\nيمكنك التواصل مع هذه المراكز للحصول على المساعدة التي تحتاجها. أتمنى لك الصحة والعافية.', 'tools_used': ['functions.health_searcher']}\", tool_call_id='call_Y0HqQ3ItnpMjJFG4xDXjrIee'),\n",
       " HumanMessage(content='هل يمكنك أن تعطيني أرقام هواتف مستشفيات التي تختص في علاج الأمراض النفسية في مصقط؟', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='بالطبع، هنا بعض أرقام الهواتف لمستشفيات ومراكز علاج الأمراض النفسية في مسقط:\\n\\n1. مركز القمة للإستشارات النفسية - مسقط: 24511010\\n2. مستشفى المسرة: +968 24 873000\\n3. دكتور نفسي في مسقط: 99019648\\n\\nيمكنك التواصل مع هذه المراكز للحصول على المساعدة التي تحتاجها. أتمنى لك الصحة والعافية.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map['abc123'].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6198a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(chat_map['abc123'].messages)):\n",
    "    if (isinstance(chat_map['abc123'].messages[i], ToolMessage)):\n",
    "        start = max(0, i - 2)\n",
    "        end = i + 1\n",
    "        chat_map['abc123'].messages = chat_map['abc123'].messages[:start] + chat_map['abc123'].messages[end:]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0af31c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:57:54,559 | INFO | Chain One Started, and default=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000023CF04CF0D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000023CF0022350>, root_client=<openai.OpenAI object at 0x0000023CEFF87650>, root_async_client=<openai.AsyncOpenAI object at 0x0000023CF0020050>, model_name='gpt-4o', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), streaming=True) fields={'callbacks': ConfigurableField(id='callbacks', name='callbacks', description='A list of callbacks to use for streaming', annotation=None, is_shared=False)} recieved User Input...\n",
      "2025-08-14 16:57:56,245 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "in_prompt : str = \\\n",
    "(\n",
    "    '''\n",
    "السلام عليكم\n",
    "\n",
    "أنا فتاة بعمر 15 سنة، أعاني من أحلام اليقظة، رغم تفوقي الدراسي، إلا أني أحس أني أعيش في عالم آخر، حيث أني فتاة محبوبة مشهورة، واثقة في نفسها، وتدرس الهندسة، وكل مرة أصنع لنفسي (سيناريو) وأعيش فيه.\n",
    "\n",
    "يمكنني القول بأن هذا العالم الذي اخترعته لي هو سبب سعادتي، لكني أحس أني لم أعد أستمتع بعالمي الحقيقي، بل أريد أي فرصة لكي أهرب إلى عالم أحلام اليقظة.\n",
    "\n",
    "أنا أعاني من الخجل الشديد، وعدم الثقة في النفس عندما أكون في الشارع أو المدرسة أحس بأن الجميع ينظر إلي، وهذا ما يجعلني أتصرف بغرابة، ومن كثرة خجلي لا أستطيع أن أرفع أصبعي في القسم.\n",
    "\n",
    "هذا يسبب لي مشكلة كبيرة، لا أعرف ما سبب عدم ثقتي في نفسي؟! فأنا واثقة من قدراتي، وأستطيع أن أحقق ما أريد، لكن في نفس الوقت لا أشعر بالراحة عندما أكون مع أي أحد باستثناء أبي وأمي وإخوتي.\n",
    "\n",
    "هذا الأمر أعاني منه منذ أربع سنوات، وكل مرة أقول لنفسي سيأتي الوقت وتتخلصين منه، لكني أرى أنه حان الوقت لأتعالج.\n",
    "\n",
    "أرجوكم ساعدوني.\n",
    "'''\n",
    ")\n",
    "out_prompt = await therapist_GPT.invoke_step1(in_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d404597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'requires_analysis': True,\n",
       " 'user_emotion': 'الخجل وعدم الثقة بالنفس',\n",
       " 'severity': 'MED',\n",
       " 'diagnosis': 'الأمراض النفسية للأطفال والمراهقين - مشاكل النمو - اضطرابات السلوك',\n",
       " 'user_prompt': 'السلام عليكم\\n\\nأنا فتاة بعمر 15 سنة، أعاني من أحلام اليقظة، رغم تفوقي الدراسي، إلا أني أحس أني أعيش في عالم آخر، حيث أني فتاة محبوبة مشهورة، واثقة في نفسها، وتدرس الهندسة، وكل مرة أصنع لنفسي (سيناريو) وأعيش فيه.\\n\\nيمكنني القول بأن هذا العالم الذي اخترعته لي هو سبب سعادتي، لكني أحس أني لم أعد أستمتع بعالمي الحقيقي، بل أريد أي فرصة لكي أهرب إلى عالم أحلام اليقظة.\\n\\nأنا أعاني من الخجل الشديد، وعدم الثقة في النفس عندما أكون في الشارع أو المدرسة أحس بأن الجميع ينظر إلي، وهذا ما يجعلني أتصرف بغرابة، ومن كثرة خجلي لا أستطيع أن أرفع أصبعي في القسم.\\n\\nهذا يسبب لي مشكلة كبيرة، لا أعرف ما سبب عدم ثقتي في نفسي؟! فأنا واثقة من قدراتي، وأستطيع أن أحقق ما أريد، لكن في نفس الوقت لا أشعر بالراحة عندما أكون مع أي أحد باستثناء أبي وأمي وإخوتي.\\n\\nهذا الأمر أعاني منه منذ أربع سنوات، وكل مرة أقول لنفسي سيأتي الوقت وتتخلصين منه، لكني أرى أنه حان الوقت لأتعالج.\\n\\nأرجوكم ساعدوني.',\n",
       " 'cbt_technique': 'التعرض التدريجي والتدريب على المهارات الاجتماعية',\n",
       " 'reason_for_technique': 'التعرض التدريجي يساعد في تقليل الخجل من خلال تعريض النفس تدريجياً للمواقف الاجتماعية التي تسبب القلق. التدريب على المهارات الاجتماعية يمكن أن يعزز الثقة بالنفس من خلال تحسين التفاعل مع الآخرين.',\n",
       " 'cultural_context': 'يمكن تعزيز الثقة بالنفس من خلال التمسك بالقيم الإسلامية مثل التوكل على الله والرضا بالنفس. كما يمكن الاستفادة من الدعم العائلي الذي يعتبر جزءاً مهماً من الثقافة العمانية.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f653dd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:58:38,039 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "out_prompt = await therapist_GPT.invoke_step2(out_prompt, session_id=\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a61f8a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "وعليكم السلام ورحمة الله وبركاته،\n",
      "\n",
      "أختي العزيزة، أولاً أود أن أهنئك على شجاعتك في التعبير عن مشاعرك والبحث عن المساعدة. من الواضح أنك تعانين من الخجل وعدم الثقة بالنفس، وهذا أمر شائع بين الكثير من الشباب في مثل عمرك.\n",
      "\n",
      "أود أن أقترح عليك تقنية العلاج السلوكي المعرفي التي تُعرف بالتعرض التدريجي والتدريب على المهارات الاجتماعية. هذه التقنية يمكن أن تساعدك في التغلب على الخجل من خلال تعريض نفسك تدريجياً للمواقف الاجتماعية التي تسبب لك القلق، مثل التحدث أمام زملائك في المدرسة أو المشاركة في الأنشطة الجماعية. يمكنك البدء بخطوات صغيرة، مثل رفع يدك للإجابة على سؤال بسيط في الصف، ثم زيادة التحديات تدريجياً.\n",
      "\n",
      "بالإضافة إلى ذلك، التدريب على المهارات الاجتماعية يمكن أن يعزز ثقتك بنفسك من خلال تحسين تفاعلك مع الآخرين. يمكنك البدء بالتحدث مع أصدقائك المقربين أو أفراد عائلتك عن مشاعرك وأفكارك، ثم توسيع دائرة التفاعل تدريجياً.\n",
      "\n",
      "لا تنسي أن التوكل على الله والرضا بالنفس هما جزء من القيم الإسلامية التي يمكن أن تعزز ثقتك بنفسك. كما أن الدعم العائلي مهم جداً، لذا حاولي التحدث مع والديك أو إخوتك عن مشاعرك وطلب دعمهم.\n",
      "\n",
      "أتمنى لك التوفيق والنجاح في رحلتك نحو تحسين ثقتك بنفسك. إذا كنت بحاجة إلى مزيد من المساعدة، لا تترددي في طلب المشورة من مختص نفسي.\n"
     ]
    }
   ],
   "source": [
    "print(out_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
