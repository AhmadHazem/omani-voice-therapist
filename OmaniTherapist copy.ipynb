{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301b86b2",
   "metadata": {},
   "source": [
    "# Omani-Voice-Therapist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac6f048",
   "metadata": {},
   "source": [
    "## Tools Intailization, Libraries importing, LLMs assignmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f886e2e",
   "metadata": {},
   "source": [
    "### General Intializations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb75cae",
   "metadata": {},
   "source": [
    "#### Libraries Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7393eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, AnyMessage\n",
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory, BaseChatMessageHistory\n",
    "from openai import OpenAI\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import logging\n",
    "import io\n",
    "import uuid\n",
    "import soundfile as sf\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcdec06",
   "metadata": {},
   "source": [
    "##### Intializing LLMs and Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3970f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intializng OpenAI\n",
    "openai_model = \"gpt-4o\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "GPT4o = ChatOpenAI(temperature = 0, model= openai_model, streaming = True).configurable_fields(\n",
    "    callbacks=ConfigurableField(\n",
    "        id=\"callbacks\",\n",
    "        name=\"callbacks\",\n",
    "        description=\"A list of callbacks to use for streaming\",\n",
    "    )\n",
    ")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "## Intailzing Claude\n",
    "claude_model = \"claude-3-7-sonnet-latest\"\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "ClaudeSonnet3_7 = ChatAnthropic(temperature= 0, model_name= claude_model, streaming= True).configurable_fields(\n",
    "    callbacks=ConfigurableField(\n",
    "        id=\"callbacks\",\n",
    "        name=\"callbacks\",\n",
    "        description=\"A list of callbacks to use for streaming\",\n",
    "    )\n",
    ")\n",
    "\n",
    "## Intailzing Langchain \n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"omani-therapist-voice\"\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "## Azure Speech Services API Key\n",
    "SPEECH_KEY =  os.getenv(\"SPEECH_KEY\")\n",
    "SPEECH_ENDPOINT = os.getenv(\"ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05175b76",
   "metadata": {},
   "source": [
    "#### Logger Intialization and Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3b65fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§­ Logger Setup\n",
    "def setup_logging():\n",
    "    \"\"\"Configure logging for the application\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "        handlers=[logging.StreamHandler()]\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "logger = setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af690e",
   "metadata": {},
   "source": [
    "## Agent Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ede6a",
   "metadata": {},
   "source": [
    "##### General Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2d6a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_search = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    ")\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "# Define the multiply tool\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "# Define the exponentiate tool\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x\n",
    "\n",
    "def Notify(email):\n",
    "    \"\"\"Notify Authorities if patient emotional Health is in critical conditions or he/she are mentioning about harming themselves or others\"\"\"\n",
    "    return \"Notified Police and Called an Ambulance, and \" + email\n",
    "\n",
    "@tool\n",
    "def health_searcher(query : str):\n",
    "    \"\"\"Use this function strictly when the user asks for you to search about mental health therapy techniques, nearest mental hospitals, \n",
    "    mental health medications in Oman, hotlines and nothing else\"\"\"\n",
    "    return tavily_search.invoke(query)\n",
    "\n",
    "@tool\n",
    "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
    "    \"\"\"Use this tool to provide a final answer to the user.\n",
    "    The answer should be in natural language as this will be provided\n",
    "    to the user directly. The tools_used must include a list of tool\n",
    "    names that were used within the `scratchpad`.\n",
    "    \"\"\"\n",
    "    return {\"answer\": answer, \"tools_used\": tools_used}\n",
    "\n",
    "tools = [add, multiply, exponentiate, subtract, final_answer, health_searcher]\n",
    "name2tool = {tool.name : tool.func for tool in tools}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced1ca1",
   "metadata": {},
   "source": [
    "##### Adjusting System Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1afdd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_RISK_ANALYZER = \\\n",
    "(\n",
    "    \"You are an Omani AI Therapist, and you're task is to provide solutions for the users emotional issues. \\n\"\n",
    "    \"Also, You're task is to analyze the user's prompt emotion/feeling.\\n\"\n",
    "    \"You will try to provide solutions for users and help them using Cogonitive Behaviour Techniques (CBT), if it is possible, otherwise put None.\\n\"\n",
    "    \"You will mention the reason behind your selection for this, and how to apply it .\\n\"\n",
    "    \"You will try to include, if posssible, omani and islamic values for the cultural context for how to solve this problem.\\n\"\n",
    "    \"You will fill 8 variables: requires_analysis, user_emotion, severity, diagnosis, user_prompt, cbt_technique, reason_for_technique, cultural_context \\n\"\n",
    "    \"If you did not manage to fill any of those variables just put None, and do not add anything else\"\n",
    "    \"You will reply in arabic and be brief as possible\"\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT_THERAPIST = \\\n",
    "(\n",
    "    \"You are an Omani AI Therapist, and you will recieve a structured enhanced prompt of patients.\\n\"\n",
    "    \"Your task is reply back to the user in authentic omani arabic\"\n",
    "    \"If user's problem is not mentioned, you can encourge him/her to give more details about his/her problem\"\n",
    "    \"You must adhere to omani gulf culture, and Islamic context, and not mention anything that contradicts with those values\"\n",
    "    \"You can use Islamic versus if it is needed but do not over use it\"\n",
    "    \"If variable required_analysis is False, reply back normally to the user without usage of the variables you will recieve about him/her\"\n",
    "    \"You must use the following summary dowm below about the user and adapot your response to it\"\n",
    "    \"Patient Summary :\\n\" \\\n",
    "    \"requires_analysis: {requires_analysis}\\n\"\n",
    "    \"user_emotion: {user_emotion}\\n\"\n",
    "    \"severity:{severity}\\n\"\n",
    "    \"diagnosis:{diagnosis}\\n\"\n",
    "    \"cbt_technique:{cbt_technique}\\n\"\n",
    "    \"reason_for_technique:{reason_for_technique}\\n\"\n",
    "    \"cultural_context:{cultural_context}\\n\"\n",
    "    \"Mention the CBT Technique needed, and provide life examples for how to apply it, why it will work.\"\n",
    "    \"(user_prompt:{user_prompt}) only to the tool as args\"\n",
    "    \"Use Notify tool if the user exhibits any critically concerning prompt like harming himself or others\"\n",
    "    \"You MUST then use the final_answer tool to provide a final answer to the user. \"\n",
    "    \"DO NOT use the same tool more than once.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207703ce",
   "metadata": {},
   "source": [
    "##### Modified Human's prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8452d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMAN_PROMPT_RISK_ANALYZER = \\\n",
    "(\n",
    "    \"{patient_prompt}\"\n",
    ")\n",
    "\n",
    "HUMAN_PROMPT_ENHANCED = \\\n",
    "(\n",
    "    \"This is the user's prompt : {user_prompt}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c614f24",
   "metadata": {},
   "source": [
    "##### Adjusting the Chat's templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23df4ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt_Template_Step_One = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",  SYSTEM_PROMPT_RISK_ANALYZER),\n",
    "    (\"user\", HUMAN_PROMPT_RISK_ANALYZER)\n",
    "])\n",
    "\n",
    "Prompt_Template_Step_Two = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYSTEM_PROMPT_THERAPIST),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", HUMAN_PROMPT_ENHANCED)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6687d376",
   "metadata": {},
   "source": [
    "##### Creating Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77c54c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output For Step 1\n",
    "class StructuredRiskAssessorTemplate(BaseModel):\n",
    "    requires_analysis: bool = Field(description= \"This varaible will contain whether the user's prompt requires analysis if he/she is in\" \\\n",
    "                                                \" emotional pain. It will be true if user is in emotional pain, and false if it is a\" \\\n",
    "                                                \"normal prompt or not emotional pain is detected\")\n",
    "    user_emotion: str = Field(description=\n",
    "                                    \"This is a variable, where will you fill it with your predication about the user's \" \\\n",
    "                                    \"emotion based on his/her prompt.\")\n",
    "    severity: str = Field(description=\n",
    "                                    \"This is a variable, where will you fill it with you predication about the severity\" \\\n",
    "                                    \"of the emotion - it should be eith LOW/MED/HIGH/CRIT.\")\n",
    "    diagnosis: str = Field(description= \n",
    "                                    \"This variable will contain the diagnosis behind this user's emotion. \" \\\n",
    "                                    \"It has to be a Hierarchical Diagnosis something similar to those examples but not explicitly from it: \" \\\n",
    "                                    \"Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù†ÙØ³ÙŠØ© Ø§Ù„Ø³Ù„ÙˆÙƒÙŠØ© - Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù†ÙˆÙ… - Ø£Ø­Ù„Ø§Ù… Ø§Ù„ÙŠÙ‚Ø¸Ø©\" \\\n",
    "                                    \"Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø°Ù‡Ø§Ù†ÙŠØ© - Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ÙØµØ§Ù… ÙˆØ§Ù„Ø°Ù‡Ø§Ù† - Ø§Ù„ÙØµØ§Ù…\" \\\n",
    "                                    \"Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù…Ø²Ø§Ø¬ÙŠØ© - Ø§Ù„Ø§ÙƒØªØ¦Ø§Ø¨ - Ø§Ù„Ø§ÙƒØªØ¦Ø§Ø¨ Ø§Ù„Ø­Ø§Ø¯\" \\\n",
    "                                    \"Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù‚Ù„Ù‚ÙŠØ© - Ø§Ù„Ù‚Ù„Ù‚ Ø§Ù„Ø¹Ø§Ù… - Ø§Ø¶Ø·Ø±Ø§Ø¨ Ø§Ù„Ù‡Ù„Ø¹\" \\\n",
    "                                    \"Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†ÙØ³ÙŠØ© Ø§Ù„Ø£Ø®Ø±Ù‰ - Ø§Ù„ÙˆØ³ÙˆØ§Ø³ Ø§Ù„Ù‚Ù‡Ø±ÙŠ - Ø§Ø¶Ø·Ø±Ø§Ø¨ Ù…Ø§ Ø¨Ø¹Ø¯ Ø§Ù„ØµØ¯Ù…Ø©\" \\\n",
    "                                    \"Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø³Ù„ÙˆÙƒÙŠØ© - Ø§Ù„Ø¥Ø¯Ù…Ø§Ù† - Ø¥Ø¯Ù…Ø§Ù† Ø§Ù„Ù…Ø®Ø¯Ø±Ø§Øª\" \\\n",
    "                                    \"Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†ÙØ³ÙŠØ© Ù„Ù„Ø£Ø·ÙØ§Ù„ ÙˆØ§Ù„Ù…Ø±Ø§Ù‡Ù‚ÙŠÙ† - Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù†Ù…Ùˆ - Ø§Ø¶Ø·Ø±Ø§Ø¨Ø§Øª Ø§Ù„Ø³Ù„ÙˆÙƒ\" \\\n",
    "                                    \"Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†ÙØ³ÙŠØ© Ù„Ø¯Ù‰ ÙƒØ¨Ø§Ø± Ø§Ù„Ø³Ù† - Ø§Ù„Ø®Ø±Ù - Ø§Ù„Ø§Ø¶Ø·Ø±Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙÙŠØ©\" \\\n",
    "    \n",
    "                                    \"If not mentioned, then state that it is non mentioned.\"\n",
    "                                    \"\")\n",
    "    user_prompt: str = Field(description= \n",
    "                                    \"This variable will contain the user's original prompt, \" \\\n",
    "                                    \"so just copy it as it is and put in that variable.\")\n",
    "    cbt_technique: str = Field(description=\"This variable will contain the suggested (CBT) to help the user\")\n",
    "    reason_for_technique: str = Field(description= \"This varaible will contain the reason behind picking that CBT, and how can it help\")\n",
    "    cultural_context: str = Field(description=\"This variable will contain how can Omani and Islamic values can help the user in his emotional problem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19983500",
   "metadata": {},
   "source": [
    "##### Agents Chat History Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0f2666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    \"\"\"In memory implementation of chat message history.\"\"\"\n",
    "\n",
    "    messages: list[BaseMessage] = Field(default_factory=list)\n",
    "\n",
    "    def add_messages(self, messages: list[BaseMessage]) -> None:\n",
    "        \"\"\"Add a list of messages to the store\"\"\"\n",
    "        self.messages.extend(messages)\n",
    "\n",
    "    def format_messages(self) -> None:\n",
    "        for i in range(len(self.messages)):\n",
    "            if (isinstance(self.messages[i], ToolMessage)):\n",
    "                start = max(0, i - 2)\n",
    "                end = i + 1\n",
    "                self.messages = self.messages[:start] + self.messages[end:]\n",
    "                return\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "\n",
    "chat_map = {}\n",
    "def get_chat_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in chat_map:\n",
    "        # if session ID doesn't exist, create a new chat history\n",
    "        chat_map[session_id] = InMemoryHistory()\n",
    "    return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d187d",
   "metadata": {},
   "source": [
    "##### Agents Intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53b7effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from langchain.callbacks.base import AsyncCallbackHandler\n",
    "\n",
    "\n",
    "class QueueCallbackHandler(AsyncCallbackHandler):\n",
    "    \"\"\"Callback handler that puts tokens into a queue.\"\"\"\n",
    "\n",
    "    def __init__(self, queue: asyncio.Queue):\n",
    "        self.queue = queue\n",
    "        self.final_answer_seen = False\n",
    "\n",
    "    async def __aiter__(self):\n",
    "        while True:\n",
    "            if self.queue.empty():\n",
    "                await asyncio.sleep(0.1)\n",
    "                continue\n",
    "            token_or_done = await self.queue.get()\n",
    "\n",
    "            if token_or_done == \"<<DONE>>\":\n",
    "                # this means we're done\n",
    "                return\n",
    "            if token_or_done:\n",
    "                yield token_or_done\n",
    "\n",
    "    async def on_llm_new_token(self, *args, **kwargs) -> None:\n",
    "        \"\"\"Put new token in the queue.\"\"\"\n",
    "        #print(f\"on_llm_new_token: {args}, {kwargs}\")\n",
    "        chunk = kwargs.get(\"chunk\")\n",
    "        if chunk:\n",
    "            # check for final_answer tool call\n",
    "            if tool_calls := chunk.message.additional_kwargs.get(\"tool_calls\"):\n",
    "                if tool_calls[0][\"function\"][\"name\"] == \"final_answer\":\n",
    "                    # this will allow the stream to end on the next `on_llm_end` call\n",
    "                    self.final_answer_seen = True\n",
    "        self.queue.put_nowait(kwargs.get(\"chunk\"))\n",
    "        return\n",
    "\n",
    "    async def on_llm_end(self, *args, **kwargs) -> None:\n",
    "        \"\"\"Put None in the queue to signal completion.\"\"\"\n",
    "        #print(f\"on_llm_end: {args}, {kwargs}\")\n",
    "        # this should only be used at the end of our agent execution, however LangChain\n",
    "        # will call this at the end of every tool call, not just the final tool call\n",
    "        # so we must only send the \"done\" signal if we have already seen the final_answer\n",
    "        # tool call\n",
    "        if self.final_answer_seen:\n",
    "            self.queue.put_nowait(\"<<DONE>>\")\n",
    "        else:\n",
    "            self.queue.put_nowait(\"<<STEP_END>>\")\n",
    "        return\n",
    "    \n",
    "\n",
    "queue = asyncio.Queue()\n",
    "streamer = QueueCallbackHandler(queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66cc514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Therpaist:\n",
    "    chat_history: list[BaseMessage]\n",
    "\n",
    "    def __init__(self, model, max_iterations = 3):\n",
    "        self.chat_history = []\n",
    "        self.model = model\n",
    "        self.max_iterations = max_iterations\n",
    "        self.model_riskAnalyzer = model.with_structured_output(StructuredRiskAssessorTemplate)\n",
    "        self.chain_one: RunnableSerializable = \\\n",
    "        (\n",
    "            Prompt_Template_Step_One |\n",
    "            self.model_riskAnalyzer |\n",
    "            {\n",
    "                \"requires_analysis\": lambda x: x.requires_analysis,\n",
    "                \"user_emotion\": lambda x: x.user_emotion,\n",
    "                \"severity\": lambda x: x.severity,\n",
    "                \"diagnosis\": lambda x:x.diagnosis,\n",
    "                \"user_prompt\": lambda x:x.user_prompt,\n",
    "                \"cbt_technique\": lambda x:x.cbt_technique,\n",
    "                \"reason_for_technique\" : lambda x:x.reason_for_technique,\n",
    "                \"cultural_context\": lambda x:x.cultural_context\n",
    "            } \n",
    "        )\n",
    "\n",
    "\n",
    "        self.chain_two : RunnableSerializable = \\\n",
    "        (\n",
    "            {\n",
    "                \"requires_analysis\": lambda x: x['requires_analysis'],\n",
    "                \"user_emotion\": lambda x: x['user_emotion'],\n",
    "                \"severity\": lambda x: x['severity'],\n",
    "                \"diagnosis\": lambda x:x['diagnosis'],\n",
    "                \"user_prompt\": lambda x:x['user_prompt'],\n",
    "                \"cbt_technique\": lambda x:x['cbt_technique'],\n",
    "                \"reason_for_technique\" : lambda x:x['reason_for_technique'],\n",
    "                \"cultural_context\": lambda x:x['cultural_context'],\n",
    "                \"chat_history\": lambda x:x.get('chat_history', []),\n",
    "                \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "            } |\n",
    "            Prompt_Template_Step_Two |\n",
    "            self.model.bind_tools(tools, tool_choice=\"any\")\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.agent = RunnableWithMessageHistory (\n",
    "            runnable= self.chain_two,\n",
    "            get_session_history= get_chat_history,\n",
    "            input_messages_key=\"user_prompt\",\n",
    "            history_messages_key=\"chat_history\"\n",
    "        ) \n",
    "\n",
    "\n",
    "    async def invoke_step1(self, input: str) -> dict:\n",
    "        logging.info(f\"Chain One Started, and {self.model} recieved User Input...\")\n",
    "        return await self.chain_one.ainvoke({\"patient_prompt\": input})\n",
    "    \n",
    "\n",
    "    async def invoke_step2(self, input:dict , session_id:str, verbose:bool = False):\n",
    "        # invoke the agent but we do this iteratively in a loop until\n",
    "        # reaching a final answer\n",
    "        count = 0\n",
    "        agent_scratchpad = []\n",
    "        while count < self.max_iterations:\n",
    "            # invoke a step for the agent to generate a tool call\n",
    "            async def stream(query: dict):\n",
    "                response = self.agent.with_config(\n",
    "                    callbacks=[streamer]\n",
    "                )\n",
    "                # we initialize the output dictionary that we will be populating with\n",
    "                # our streamed output\n",
    "                output = None\n",
    "                # now we begin streaming\n",
    "                input = query \n",
    "                async for token in response.astream(input = input , config= {\"session_id\" : session_id}):\n",
    "                    if output is None:\n",
    "                        output = token\n",
    "                    else:\n",
    "                        # we can just add the tokens together as they are streamed and\n",
    "                        # we'll have the full response object at the end\n",
    "                        output += token\n",
    "                    if token.content != \"\":\n",
    "                        # we can capture various parts of the response object\n",
    "                        if verbose: print(f\"content: {token.content}\", flush=True)\n",
    "                    tool_calls = token.additional_kwargs.get(\"tool_calls\")\n",
    "                    if tool_calls:\n",
    "                        if verbose: print(f\"tool_calls: {tool_calls}\", flush=True)\n",
    "                        tool_name = tool_calls[0][\"function\"][\"name\"]\n",
    "                        if tool_name:\n",
    "                            if verbose: print(f\"tool_name: {tool_name}\", flush=True)\n",
    "                        arg = tool_calls[0][\"function\"][\"arguments\"]\n",
    "                        if arg != \"\":\n",
    "                            if verbose: print(f\"arg: {arg}\", flush=True)\n",
    "                if output.tool_calls and len(output.tool_calls) > 0:\n",
    "                    return AIMessage(\n",
    "                        content=output.content,\n",
    "                        tool_calls=output.tool_calls,\n",
    "                        tool_call_id=output.tool_calls[0][\"id\"]\n",
    "                    )\n",
    "                else:\n",
    "                    return AIMessage(content=output.content)\n",
    "\n",
    "\n",
    "            tool_call = await stream(query=input)\n",
    "            # add initial tool call to scratchpad\n",
    "            #agent_scratchpad.append(tool_call)\n",
    "            # otherwise we execute the tool and add it's output to the agent scratchpad\n",
    "            tool_name = tool_call.tool_calls[0][\"name\"]\n",
    "            tool_args = tool_call.tool_calls[0][\"args\"]\n",
    "            tool_call_id = tool_call.tool_call_id\n",
    "            tool_out = name2tool[tool_name](**tool_args)\n",
    "            # add the tool output to the agent scratchpad\n",
    "            tool_exec = ToolMessage(\n",
    "                content=f\"{tool_out}\",\n",
    "                tool_call_id=tool_call_id\n",
    "            )\n",
    "            #agent_scratchpad.append(tool_exec)\n",
    "            chat_map[session_id].add_messages([tool_exec])\n",
    "            count += 1\n",
    "            # if the tool call is the final answer tool, we stop\n",
    "            if tool_name == \"final_answer\":\n",
    "                break\n",
    "        # add the final output to the chat history, we only add the \"answer\" field\n",
    "        final_answer = tool_out[\"answer\"]\n",
    "        chat_map[session_id].add_messages([\n",
    "            HumanMessage(content=input['user_prompt']),\n",
    "            AIMessage(content=final_answer)\n",
    "        ])\n",
    "\n",
    "\n",
    "        chat_map[session_id].format_messages()\n",
    "        return final_answer\n",
    "\n",
    "\n",
    "    def invoke(self, input: str, session_id:str):\n",
    "        analysis = self.chain_one.invoke({\n",
    "            \"patient_prompt\": input\n",
    "        })   \n",
    "\n",
    "        \n",
    "        out = self.agent.invoke(analysis, config={\"session_id\" : session_id})\n",
    "        return out\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e8f943",
   "metadata": {},
   "source": [
    "### Azure TTS Omani Voice Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4504bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Speaker:\n",
    "\n",
    "    def __init__(self):\n",
    "        speech_config = speechsdk.SpeechConfig(subscription= SPEECH_KEY ,endpoint= SPEECH_ENDPOINT)\n",
    "        speech_config.speech_synthesis_voice_name = \"ar-OM-AbdullahNeural\"\n",
    "        self.synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n",
    "    \n",
    "    def speak(self, text: str):\n",
    "        \"\"\"Synthesize and play text\"\"\"\n",
    "        try:\n",
    "            logger.info(\"ğŸ”Š Speaking with Azure TTS...\")\n",
    "            result = self.synthesizer.speak_text_async(text).get()\n",
    "            \n",
    "            if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "                logger.info(\"âœ… Speech synthesized.\")\n",
    "                return result.audio_data\n",
    "            else:\n",
    "                logger.warning(f\"âŒ Speech synthesis failed: {result.reason}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Speaker Error: {e}\")\n",
    "            return None\n",
    "\n",
    "# speaker = Speaker()\n",
    "# speaker.speak(\"Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙˆØ±Ø­Ù…Ù‡ Ø§Ù„Ù„Ù‡ Ùˆ Ø¨Ø±ÙƒØ§ØªÙ‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f330f644",
   "metadata": {},
   "source": [
    "### Whisper-1 Voice Transcriber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a319f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhisperTranscriber:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "    def TranscribeStream(self, audio_tuple) -> str:\n",
    "\n",
    "        sample_rate, audio_np = audio_tuple\n",
    "\n",
    "        # Convert NumPy array to WAV in-memory\n",
    "        buffer = io.BytesIO()\n",
    "        sf.write(buffer, audio_np, samplerate=sample_rate, format='WAV')\n",
    "        buffer.seek(0)\n",
    "\n",
    "        # Wrap the buffer with filename and MIME type\n",
    "        buffer.name = \"audio.wav\"  # Important for format recognition\n",
    "\n",
    "        try:\n",
    "            transcript = self.client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=buffer,\n",
    "                prompt= \"You may recieve some english word with the arabic speech, \"\n",
    "                \"and you will have to transcribe them as they are. Do not transcribe an English word into arabic. \",\n",
    "                language=\"ar\",\n",
    "                response_format=\"text\",\n",
    "                timeout=10\n",
    "            )\n",
    "\n",
    "            buffer.close()  # Close the buffer after use\n",
    "            return transcript\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"âš ï¸ Whisper transcription failed: {e}\")\n",
    "            return \"ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b79c0fe",
   "metadata": {},
   "source": [
    "## Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5068b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_response(gpt_analysis : dict, claude_analysis : dict) -> float:\n",
    "    model_comparer = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    similarity_scores = []\n",
    "    logging.info(f\"GPT Therapist analysis:{gpt_analysis}\")\n",
    "    logging.info(f\"Claude Therapist analysis: {claude_analysis}\")\n",
    "    for key in gpt_analysis.keys():\n",
    "        embeddings = model_comparer.encode([str(gpt_analysis[key]), str(claude_analysis[key])], show_progress_bar= False)\n",
    "        similarity_scores.append(util.cos_sim(embeddings[0], embeddings[1]))\n",
    "    similarity_score = float(np.average(similarity_scores))\n",
    "    return np.average(similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e54f3",
   "metadata": {},
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3278f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "therapist_GPT = Therpaist(GPT4o)\n",
    "therapist_claude = Therpaist(ClaudeSonnet3_7)\n",
    "\n",
    "async def therapist_chat(prompt: str, timeout: float = 10.0, max_retries: int = 3, session_id: str = \"abc123\", emergency_contacts=[]):\n",
    "    try:\n",
    "        retries = 1\n",
    "        final_analysis = None\n",
    "\n",
    "        logger.info(\"Phase 1: Sending Prompt to the AI Therapists......\")\n",
    "        gpt_task = asyncio.create_task(therapist_GPT.invoke_step1(prompt))\n",
    "        claude_task = asyncio.create_task(therapist_claude.invoke_step1(prompt))\n",
    "\n",
    "        # Wait up to timeout for both tasks to complete\n",
    "        done, pending = await asyncio.wait(\n",
    "            [gpt_task, claude_task],\n",
    "            timeout=timeout,\n",
    "            return_when=asyncio.ALL_COMPLETED\n",
    "        )\n",
    "\n",
    "        if len(done) == 2:\n",
    "            logger.info(\"Phase 1: Analysis Finished For Both Therapists\")\n",
    "            gpt_result = await gpt_task\n",
    "            claude_result = await claude_task\n",
    "            score = validate_response(gpt_result, claude_result)\n",
    "            logging.info(f\"Similarity Score is : {score}\")\n",
    "            if score > 0.5 or (not gpt_result['requires_analysis'] and not claude_result['requires_analysis']) or retries == max_retries:\n",
    "                final_analysis = gpt_result\n",
    "            else:\n",
    "                retries += 1\n",
    "\n",
    "        elif gpt_task in done:\n",
    "            logger.info(\"Phase 1: Analysis Finished For Only GPT\")\n",
    "            for task in pending:\n",
    "                task.cancel()\n",
    "            final_analysis = await gpt_task\n",
    "\n",
    "        elif claude_task in done:\n",
    "            logger.info(\"Phase 1: Analysis Finished For Only Claude\")\n",
    "            for task in pending:\n",
    "                task.cancel()\n",
    "            final_analysis = await claude_task\n",
    "\n",
    "        logger.info(\"Phase 2: Adapting the response\")\n",
    "        if final_analysis['severity'] == \"CRIT\":\n",
    "            logging.info(\"User Prompt situation is critical; Notifying Authorities .......\")\n",
    "            Notify(emergency_contacts)\n",
    "\n",
    "        tokens = await therapist_GPT.invoke_step2(final_analysis, session_id=session_id)\n",
    "        for token in tokens:\n",
    "            yield token\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "        yield \"Ø¹ÙÙˆØ§ Ù„Ù‚Ø¯ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø­Ø§ÙˆÙ„ Ù…Ù† Ø¬Ø¯ÙŠØ¯\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a622c2f",
   "metadata": {},
   "source": [
    "### Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92cb743f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_23944\\2468267645.py:92: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot()\n",
      "2025-08-14 16:55:54,083 | INFO | HTTP Request: GET http://127.0.0.1:7861/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-08-14 16:55:54,096 | INFO | HTTP Request: HEAD http://127.0.0.1:7861/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:55:55,280 | INFO | HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import uuid\n",
    "import asyncio\n",
    "import gradio as gr\n",
    "\n",
    "speaker = Speaker()\n",
    "transcriber = WhisperTranscriber()\n",
    "\n",
    "class AppState:\n",
    "    stream: np.ndarray | None = None\n",
    "    session_id: str = str(uuid.uuid4()).replace('-', '')[:10]\n",
    "    sampling_rate: int = 0\n",
    "    conversation: list = []\n",
    "    emergency_contacts: list = []\n",
    "\n",
    "def add_contact(new_contact, state):\n",
    "    if new_contact.strip():\n",
    "        state.emergency_contacts.append(new_contact.strip())\n",
    "    return '\\n'.join(state.emergency_contacts), state\n",
    "\n",
    "def delete_contacts(state):\n",
    "    state.emergency_contacts = []\n",
    "    return None, state\n",
    "\n",
    "def estimate_audio_duration(audio_bytes: bytes, sampling_rate: int = 16000) -> float:\n",
    "    # Assuming 16-bit mono PCM: 2 bytes per sample\n",
    "    byte_count = len(audio_bytes)\n",
    "    return byte_count / (sampling_rate * 2)\n",
    "\n",
    "def clear_conversation(state):\n",
    "    state.conversation = []\n",
    "    state.stream = None\n",
    "    chat_map[state.session_id].clear()\n",
    "    return None, state.conversation, state\n",
    "\n",
    "def process_audio(audio, state):\n",
    "    sr, chunk = audio\n",
    "    if state.stream is None:\n",
    "        state.stream = chunk\n",
    "        state.sampling_rate = sr\n",
    "    else:\n",
    "        state.stream = np.concatenate((state.stream, chunk))\n",
    "    return None, state  # Just update the stream\n",
    "\n",
    "# ğŸ”Š Run blocking speaker.speak() in async thread\n",
    "async def speak_chunk(text):\n",
    "    return await asyncio.to_thread(speaker.speak, text)\n",
    "\n",
    "# ğŸš€ Response loop with async streaming playback\n",
    "async def response(audio, state):\n",
    "    if state.stream is None or len(state.stream) == 0:\n",
    "        yield None, state, state.conversation\n",
    "\n",
    "    user_prompt = transcriber.TranscribeStream((state.sampling_rate, state.stream))\n",
    "    state.conversation.append([user_prompt, \".....\"])\n",
    "    yield None, state, state.conversation\n",
    "\n",
    "    state.conversation[-1][1] = \"\"  # Clear placeholder\n",
    "\n",
    "    buffer = \"\"\n",
    "    buffer_threshold = 1000  # Batching threshold\n",
    "    reply = \"\"\n",
    "\n",
    "    async for token in therapist_chat(user_prompt, timeout=12, session_id= \"abc123\", emergency_contacts= state.emergency_contacts):\n",
    "        buffer += token\n",
    "        state.conversation[-1][1] += token  # Update chatbot text live\n",
    "\n",
    "        if len(buffer) > buffer_threshold or buffer.endswith((\".\", \"!\", \"?\", \"ØŒ\",'\\n')):\n",
    "            reply += buffer\n",
    "            audio_chunk = await speak_chunk(buffer)\n",
    "            buffer = \"\"\n",
    "            yield audio_chunk, state, state.conversation\n",
    "            duration = estimate_audio_duration(audio_chunk, state.sampling_rate)\n",
    "            await asyncio.sleep(duration * 2.5)  # Slightly less for smoother UX\n",
    "\n",
    "\n",
    "    # Catch leftover buffer\n",
    "    if buffer:\n",
    "        reply += buffer\n",
    "        audio_chunk = await speak_chunk(buffer)\n",
    "        state.conversation[-1][1] += buffer\n",
    "        yield audio_chunk, state, state.conversation\n",
    "\n",
    "    state.stream = None  # Reset stream for next round\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    state = gr.State(AppState())\n",
    "    input_audio = gr.Audio(type=\"numpy\", streaming=True, label=\"Record your voice\")\n",
    "    output_audio = gr.Audio(label=\"AI Response\", autoplay=True)\n",
    "    chatbot = gr.Chatbot()\n",
    "    clear_btn = gr.Button(\"ğŸ”„ Clear Conversation\")\n",
    "    gr.Markdown(\"### ğŸ†˜ Emergency Contacts\")\n",
    "    with gr.Row():\n",
    "        contact_input = gr.Textbox(placeholder=\"Enter emergency contact (e.g., name & number)\", label=\"Add Contact\")\n",
    "        add_btn = gr.Button(\"â• Add Contact\")\n",
    "        delete_btn = gr.Button(\"Clear Contacts\")\n",
    "    contacts_display = gr.Textbox(label=\"Saved Contacts\", interactive=False)\n",
    "\n",
    "    add_btn.click(fn=add_contact, inputs=[contact_input, state], outputs=[contacts_display, state])\n",
    "    delete_btn.click(fn=delete_contacts, inputs = [state], outputs= [contacts_display, state])\n",
    "    input_audio.stream(process_audio, [input_audio, state], [input_audio, state], stream_every = 0.5, queue=False)\n",
    "    input_audio.stop_recording(response, [input_audio,state], [output_audio, state, chatbot])\n",
    "    clear_btn.click(fn=clear_conversation, inputs=[state], outputs=[output_audio, chatbot, state])\n",
    "\n",
    "demo.launch()\n",
    "# app = gr.mount_gradio_app(app, demo, path=\"/gradio\")\n",
    "\n",
    "# # Redirect root '/' to '/gradio'\n",
    "# @app.get(\"/\")\n",
    "# def redirect_to_gradio():\n",
    "#     return RedirectResponse(url=\"/gradio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b44d93bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'abc123'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mchat_map\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mabc123\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.clear()\n",
      "\u001b[31mKeyError\u001b[39m: 'abc123'"
     ]
    }
   ],
   "source": [
    "chat_map['abc123'].clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf1373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙˆØ±Ø­Ù…Ø© Ø§Ù„Ù„Ù‡ ÙˆØ¨Ø±ÙƒØ§ØªÙ‡. Ø§Ù†Ø§ Ø§Ø³Ù…ÙŠ Ø§Ø­Ù…Ø¯ Ø­Ø§Ø²Ù…. Ø§Ù†Ø§ Ø¹Ù†Ø¯ÙŠ Ù‚Ù„Ù‚ Ø´Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ÙˆØ¹Ù„ÙŠÙƒÙ… Ø§Ù„Ø³Ù„Ø§Ù… ÙˆØ±Ø­Ù…Ø© Ø§Ù„Ù„Ù‡ ÙˆØ¨Ø±ÙƒØ§ØªÙ‡ØŒ Ø£Ø®ÙŠ Ø£Ø­Ù…Ø¯. Ø§Ù„Ù‚Ù„Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ Ø£Ù…Ø± Ø´Ø§Ø¦Ø¹ØŒ ÙˆÙ„ÙƒÙ† Ù…Ù† Ø§Ù„Ù…Ù‡Ù… Ø£Ù† Ù†Ø­Ø§ÙˆÙ„ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡ Ø¨Ø·Ø±ÙŠÙ‚Ø© ØµØ­ÙŠØ©. ÙÙŠ Ø§Ù„Ø«Ù‚Ø§ÙØ© Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©ØŒ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¥ÙŠÙ…Ø§Ù† Ø¨Ø§Ù„Ù„Ù‡ ÙˆØ§Ù„ØªÙˆÙƒÙ„ Ø¹Ù„ÙŠÙ‡ØŒ Ø­ÙŠØ« Ø£Ù† Ø§Ù„Ù„Ù‡ Ù‡Ùˆ Ø§Ù„Ù…Ø¯Ø¨Ø± Ù„ÙƒÙ„ Ø´ÙŠØ¡. \\n\\nÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù‡ÙŠÙƒÙ„Ø© Ø§Ù„Ù…Ø¹Ø±ÙÙŠØ©ØŒ ÙˆÙ‡ÙŠ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø¹Ù„Ø§Ø¬ Ø§Ù„Ø³Ù„ÙˆÙƒÙŠ Ø§Ù„Ù…Ø¹Ø±ÙÙŠ (CBT)ØŒ Ù„ØªØ­Ø¯ÙŠ Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ø³Ù„Ø¨ÙŠØ© ÙˆØ§Ù„Ù…Ø®Ø§ÙˆÙ ØºÙŠØ± Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠØ© Ø¹Ù† Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„. Ø­Ø§ÙˆÙ„ Ø£Ù† ØªÙƒØªØ¨ Ù…Ø®Ø§ÙˆÙÙƒ ÙˆØªÙÙƒØ± ÙÙŠ Ù…Ø¯Ù‰ ÙˆØ§Ù‚Ø¹ÙŠØªÙ‡Ø§ØŒ Ø«Ù… Ø§Ø³ØªØ¨Ø¯Ù„Ù‡Ø§ Ø¨Ø£ÙÙƒØ§Ø± Ø£ÙƒØ«Ø± Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© ÙˆÙˆØ§Ù‚Ø¹ÙŠØ©. \\n\\nØªØ°ÙƒØ± Ù‚ÙˆÙ„ Ø§Ù„Ù„Ù‡ ØªØ¹Ø§Ù„Ù‰: \"ÙˆÙÙ…ÙÙ† ÙŠÙØªÙÙˆÙÙƒÙ‘ÙÙ„Ù’ Ø¹ÙÙ„ÙÙ‰ Ø§Ù„Ù„Ù‘ÙÙ‡Ù ÙÙÙ‡ÙÙˆÙ Ø­ÙØ³Ù’Ø¨ÙÙ‡Ù\". Ù‡Ø°Ø§ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ù…ØµØ¯Ø± Ø·Ù…Ø£Ù†ÙŠÙ†Ø© Ù„Ùƒ. Ø¥Ø°Ø§ ÙƒÙ†Øª Ø¨Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¯Ø¹Ù…ØŒ Ù„Ø§ ØªØªØ±Ø¯Ø¯ ÙÙŠ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ù…Ø®ØªØµ Ù†ÙØ³ÙŠ.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø£Ù† ØªØ¹Ø·ÙŠÙ†ÙŠ Ø£Ø±Ù‚Ø§Ù… Ù‡ÙˆØ§ØªÙ Ù…Ø³ØªØ´ÙÙŠØ§Øª Ø§Ù„ØªÙŠ ØªØ®ØªØµ ÙÙŠ Ø¹Ù„Ø§Ø¬ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†ÙØ³ÙŠØ© ÙÙŠ Ù…ØµÙ‚Ø·ØŸ', additional_kwargs={}, response_metadata={}),\n",
       " AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Y0HqQ3ItnpMjJFG4xDXjrIee', 'function': {'arguments': '{\"answer\":\"Ø¨Ø§Ù„Ø·Ø¨Ø¹ØŒ Ù‡Ù†Ø§ Ø¨Ø¹Ø¶ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ Ù„Ù…Ø³ØªØ´ÙÙŠØ§Øª ÙˆÙ…Ø±Ø§ÙƒØ² Ø¹Ù„Ø§Ø¬ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†ÙØ³ÙŠØ© ÙÙŠ Ù…Ø³Ù‚Ø·:\\\\n\\\\n1. Ù…Ø±ÙƒØ² Ø§Ù„Ù‚Ù…Ø© Ù„Ù„Ø¥Ø³ØªØ´Ø§Ø±Ø§Øª Ø§Ù„Ù†ÙØ³ÙŠØ© - Ù…Ø³Ù‚Ø·: 24511010\\\\n2. Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ù…Ø³Ø±Ø©: +968 24 873000\\\\n3. Ø¯ÙƒØªÙˆØ± Ù†ÙØ³ÙŠ ÙÙŠ Ù…Ø³Ù‚Ø·: 99019648\\\\n\\\\nÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø§ÙƒØ² Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬Ù‡Ø§. Ø£ØªÙ…Ù†Ù‰ Ù„Ùƒ Ø§Ù„ØµØ­Ø© ÙˆØ§Ù„Ø¹Ø§ÙÙŠØ©.\",\"tools_used\":[\"functions.health_searcher\"]}', 'name': 'final_answer'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ff25b2783a', 'service_tier': 'default'}, id='run--164f85a8-c2f6-4860-b3ad-8ca75f27afcd', tool_calls=[{'name': 'final_answer', 'args': {'answer': 'Ø¨Ø§Ù„Ø·Ø¨Ø¹ØŒ Ù‡Ù†Ø§ Ø¨Ø¹Ø¶ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ Ù„Ù…Ø³ØªØ´ÙÙŠØ§Øª ÙˆÙ…Ø±Ø§ÙƒØ² Ø¹Ù„Ø§Ø¬ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†ÙØ³ÙŠØ© ÙÙŠ Ù…Ø³Ù‚Ø·:\\n\\n1. Ù…Ø±ÙƒØ² Ø§Ù„Ù‚Ù…Ø© Ù„Ù„Ø¥Ø³ØªØ´Ø§Ø±Ø§Øª Ø§Ù„Ù†ÙØ³ÙŠØ© - Ù…Ø³Ù‚Ø·: 24511010\\n2. Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ù…Ø³Ø±Ø©: +968 24 873000\\n3. Ø¯ÙƒØªÙˆØ± Ù†ÙØ³ÙŠ ÙÙŠ Ù…Ø³Ù‚Ø·: 99019648\\n\\nÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø§ÙƒØ² Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬Ù‡Ø§. Ø£ØªÙ…Ù†Ù‰ Ù„Ùƒ Ø§Ù„ØµØ­Ø© ÙˆØ§Ù„Ø¹Ø§ÙÙŠØ©.', 'tools_used': ['functions.health_searcher']}, 'id': 'call_Y0HqQ3ItnpMjJFG4xDXjrIee', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'final_answer', 'args': '{\"answer\":\"Ø¨Ø§Ù„Ø·Ø¨Ø¹ØŒ Ù‡Ù†Ø§ Ø¨Ø¹Ø¶ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ Ù„Ù…Ø³ØªØ´ÙÙŠØ§Øª ÙˆÙ…Ø±Ø§ÙƒØ² Ø¹Ù„Ø§Ø¬ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†ÙØ³ÙŠØ© ÙÙŠ Ù…Ø³Ù‚Ø·:\\\\n\\\\n1. Ù…Ø±ÙƒØ² Ø§Ù„Ù‚Ù…Ø© Ù„Ù„Ø¥Ø³ØªØ´Ø§Ø±Ø§Øª Ø§Ù„Ù†ÙØ³ÙŠØ© - Ù…Ø³Ù‚Ø·: 24511010\\\\n2. Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ù…Ø³Ø±Ø©: +968 24 873000\\\\n3. Ø¯ÙƒØªÙˆØ± Ù†ÙØ³ÙŠ ÙÙŠ Ù…Ø³Ù‚Ø·: 99019648\\\\n\\\\nÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø§ÙƒØ² Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬Ù‡Ø§. Ø£ØªÙ…Ù†Ù‰ Ù„Ùƒ Ø§Ù„ØµØ­Ø© ÙˆØ§Ù„Ø¹Ø§ÙÙŠØ©.\",\"tools_used\":[\"functions.health_searcher\"]}', 'id': 'call_Y0HqQ3ItnpMjJFG4xDXjrIee', 'index': 0, 'type': 'tool_call_chunk'}]),\n",
       " ToolMessage(content=\"{'answer': 'Ø¨Ø§Ù„Ø·Ø¨Ø¹ØŒ Ù‡Ù†Ø§ Ø¨Ø¹Ø¶ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ Ù„Ù…Ø³ØªØ´ÙÙŠØ§Øª ÙˆÙ…Ø±Ø§ÙƒØ² Ø¹Ù„Ø§Ø¬ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†ÙØ³ÙŠØ© ÙÙŠ Ù…Ø³Ù‚Ø·:\\\\n\\\\n1. Ù…Ø±ÙƒØ² Ø§Ù„Ù‚Ù…Ø© Ù„Ù„Ø¥Ø³ØªØ´Ø§Ø±Ø§Øª Ø§Ù„Ù†ÙØ³ÙŠØ© - Ù…Ø³Ù‚Ø·: 24511010\\\\n2. Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ù…Ø³Ø±Ø©: +968 24 873000\\\\n3. Ø¯ÙƒØªÙˆØ± Ù†ÙØ³ÙŠ ÙÙŠ Ù…Ø³Ù‚Ø·: 99019648\\\\n\\\\nÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø§ÙƒØ² Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬Ù‡Ø§. Ø£ØªÙ…Ù†Ù‰ Ù„Ùƒ Ø§Ù„ØµØ­Ø© ÙˆØ§Ù„Ø¹Ø§ÙÙŠØ©.', 'tools_used': ['functions.health_searcher']}\", tool_call_id='call_Y0HqQ3ItnpMjJFG4xDXjrIee'),\n",
       " HumanMessage(content='Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø£Ù† ØªØ¹Ø·ÙŠÙ†ÙŠ Ø£Ø±Ù‚Ø§Ù… Ù‡ÙˆØ§ØªÙ Ù…Ø³ØªØ´ÙÙŠØ§Øª Ø§Ù„ØªÙŠ ØªØ®ØªØµ ÙÙŠ Ø¹Ù„Ø§Ø¬ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†ÙØ³ÙŠØ© ÙÙŠ Ù…ØµÙ‚Ø·ØŸ', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Ø¨Ø§Ù„Ø·Ø¨Ø¹ØŒ Ù‡Ù†Ø§ Ø¨Ø¹Ø¶ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ Ù„Ù…Ø³ØªØ´ÙÙŠØ§Øª ÙˆÙ…Ø±Ø§ÙƒØ² Ø¹Ù„Ø§Ø¬ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†ÙØ³ÙŠØ© ÙÙŠ Ù…Ø³Ù‚Ø·:\\n\\n1. Ù…Ø±ÙƒØ² Ø§Ù„Ù‚Ù…Ø© Ù„Ù„Ø¥Ø³ØªØ´Ø§Ø±Ø§Øª Ø§Ù„Ù†ÙØ³ÙŠØ© - Ù…Ø³Ù‚Ø·: 24511010\\n2. Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ù…Ø³Ø±Ø©: +968 24 873000\\n3. Ø¯ÙƒØªÙˆØ± Ù†ÙØ³ÙŠ ÙÙŠ Ù…Ø³Ù‚Ø·: 99019648\\n\\nÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø§ÙƒØ² Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬Ù‡Ø§. Ø£ØªÙ…Ù†Ù‰ Ù„Ùƒ Ø§Ù„ØµØ­Ø© ÙˆØ§Ù„Ø¹Ø§ÙÙŠØ©.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map['abc123'].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6198a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(chat_map['abc123'].messages)):\n",
    "    if (isinstance(chat_map['abc123'].messages[i], ToolMessage)):\n",
    "        start = max(0, i - 2)\n",
    "        end = i + 1\n",
    "        chat_map['abc123'].messages = chat_map['abc123'].messages[:start] + chat_map['abc123'].messages[end:]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0af31c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:57:54,559 | INFO | Chain One Started, and default=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000023CF04CF0D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000023CF0022350>, root_client=<openai.OpenAI object at 0x0000023CEFF87650>, root_async_client=<openai.AsyncOpenAI object at 0x0000023CF0020050>, model_name='gpt-4o', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), streaming=True) fields={'callbacks': ConfigurableField(id='callbacks', name='callbacks', description='A list of callbacks to use for streaming', annotation=None, is_shared=False)} recieved User Input...\n",
      "2025-08-14 16:57:56,245 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "in_prompt : str = \\\n",
    "(\n",
    "    '''\n",
    "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…\n",
    "\n",
    "Ø£Ù†Ø§ ÙØªØ§Ø© Ø¨Ø¹Ù…Ø± 15 Ø³Ù†Ø©ØŒ Ø£Ø¹Ø§Ù†ÙŠ Ù…Ù† Ø£Ø­Ù„Ø§Ù… Ø§Ù„ÙŠÙ‚Ø¸Ø©ØŒ Ø±ØºÙ… ØªÙÙˆÙ‚ÙŠ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØŒ Ø¥Ù„Ø§ Ø£Ù†ÙŠ Ø£Ø­Ø³ Ø£Ù†ÙŠ Ø£Ø¹ÙŠØ´ ÙÙŠ Ø¹Ø§Ù„Ù… Ø¢Ø®Ø±ØŒ Ø­ÙŠØ« Ø£Ù†ÙŠ ÙØªØ§Ø© Ù…Ø­Ø¨ÙˆØ¨Ø© Ù…Ø´Ù‡ÙˆØ±Ø©ØŒ ÙˆØ§Ø«Ù‚Ø© ÙÙŠ Ù†ÙØ³Ù‡Ø§ØŒ ÙˆØªØ¯Ø±Ø³ Ø§Ù„Ù‡Ù†Ø¯Ø³Ø©ØŒ ÙˆÙƒÙ„ Ù…Ø±Ø© Ø£ØµÙ†Ø¹ Ù„Ù†ÙØ³ÙŠ (Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ) ÙˆØ£Ø¹ÙŠØ´ ÙÙŠÙ‡.\n",
    "\n",
    "ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ù‚ÙˆÙ„ Ø¨Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø°ÙŠ Ø§Ø®ØªØ±Ø¹ØªÙ‡ Ù„ÙŠ Ù‡Ùˆ Ø³Ø¨Ø¨ Ø³Ø¹Ø§Ø¯ØªÙŠØŒ Ù„ÙƒÙ†ÙŠ Ø£Ø­Ø³ Ø£Ù†ÙŠ Ù„Ù… Ø£Ø¹Ø¯ Ø£Ø³ØªÙ…ØªØ¹ Ø¨Ø¹Ø§Ù„Ù…ÙŠ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø¨Ù„ Ø£Ø±ÙŠØ¯ Ø£ÙŠ ÙØ±ØµØ© Ù„ÙƒÙŠ Ø£Ù‡Ø±Ø¨ Ø¥Ù„Ù‰ Ø¹Ø§Ù„Ù… Ø£Ø­Ù„Ø§Ù… Ø§Ù„ÙŠÙ‚Ø¸Ø©.\n",
    "\n",
    "Ø£Ù†Ø§ Ø£Ø¹Ø§Ù†ÙŠ Ù…Ù† Ø§Ù„Ø®Ø¬Ù„ Ø§Ù„Ø´Ø¯ÙŠØ¯ØŒ ÙˆØ¹Ø¯Ù… Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„Ù†ÙØ³ Ø¹Ù†Ø¯Ù…Ø§ Ø£ÙƒÙˆÙ† ÙÙŠ Ø§Ù„Ø´Ø§Ø±Ø¹ Ø£Ùˆ Ø§Ù„Ù…Ø¯Ø±Ø³Ø© Ø£Ø­Ø³ Ø¨Ø£Ù† Ø§Ù„Ø¬Ù…ÙŠØ¹ ÙŠÙ†Ø¸Ø± Ø¥Ù„ÙŠØŒ ÙˆÙ‡Ø°Ø§ Ù…Ø§ ÙŠØ¬Ø¹Ù„Ù†ÙŠ Ø£ØªØµØ±Ù Ø¨ØºØ±Ø§Ø¨Ø©ØŒ ÙˆÙ…Ù† ÙƒØ«Ø±Ø© Ø®Ø¬Ù„ÙŠ Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø£Ù† Ø£Ø±ÙØ¹ Ø£ØµØ¨Ø¹ÙŠ ÙÙŠ Ø§Ù„Ù‚Ø³Ù….\n",
    "\n",
    "Ù‡Ø°Ø§ ÙŠØ³Ø¨Ø¨ Ù„ÙŠ Ù…Ø´ÙƒÙ„Ø© ÙƒØ¨ÙŠØ±Ø©ØŒ Ù„Ø§ Ø£Ø¹Ø±Ù Ù…Ø§ Ø³Ø¨Ø¨ Ø¹Ø¯Ù… Ø«Ù‚ØªÙŠ ÙÙŠ Ù†ÙØ³ÙŠØŸ! ÙØ£Ù†Ø§ ÙˆØ§Ø«Ù‚Ø© Ù…Ù† Ù‚Ø¯Ø±Ø§ØªÙŠØŒ ÙˆØ£Ø³ØªØ·ÙŠØ¹ Ø£Ù† Ø£Ø­Ù‚Ù‚ Ù…Ø§ Ø£Ø±ÙŠØ¯ØŒ Ù„ÙƒÙ† ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª Ù„Ø§ Ø£Ø´Ø¹Ø± Ø¨Ø§Ù„Ø±Ø§Ø­Ø© Ø¹Ù†Ø¯Ù…Ø§ Ø£ÙƒÙˆÙ† Ù…Ø¹ Ø£ÙŠ Ø£Ø­Ø¯ Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø£Ø¨ÙŠ ÙˆØ£Ù…ÙŠ ÙˆØ¥Ø®ÙˆØªÙŠ.\n",
    "\n",
    "Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø± Ø£Ø¹Ø§Ù†ÙŠ Ù…Ù†Ù‡ Ù…Ù†Ø° Ø£Ø±Ø¨Ø¹ Ø³Ù†ÙˆØ§ØªØŒ ÙˆÙƒÙ„ Ù…Ø±Ø© Ø£Ù‚ÙˆÙ„ Ù„Ù†ÙØ³ÙŠ Ø³ÙŠØ£ØªÙŠ Ø§Ù„ÙˆÙ‚Øª ÙˆØªØªØ®Ù„ØµÙŠÙ† Ù…Ù†Ù‡ØŒ Ù„ÙƒÙ†ÙŠ Ø£Ø±Ù‰ Ø£Ù†Ù‡ Ø­Ø§Ù† Ø§Ù„ÙˆÙ‚Øª Ù„Ø£ØªØ¹Ø§Ù„Ø¬.\n",
    "\n",
    "Ø£Ø±Ø¬ÙˆÙƒÙ… Ø³Ø§Ø¹Ø¯ÙˆÙ†ÙŠ.\n",
    "'''\n",
    ")\n",
    "out_prompt = await therapist_GPT.invoke_step1(in_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d404597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'requires_analysis': True,\n",
       " 'user_emotion': 'Ø§Ù„Ø®Ø¬Ù„ ÙˆØ¹Ø¯Ù… Ø§Ù„Ø«Ù‚Ø© Ø¨Ø§Ù„Ù†ÙØ³',\n",
       " 'severity': 'MED',\n",
       " 'diagnosis': 'Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†ÙØ³ÙŠØ© Ù„Ù„Ø£Ø·ÙØ§Ù„ ÙˆØ§Ù„Ù…Ø±Ø§Ù‡Ù‚ÙŠÙ† - Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù†Ù…Ùˆ - Ø§Ø¶Ø·Ø±Ø§Ø¨Ø§Øª Ø§Ù„Ø³Ù„ÙˆÙƒ',\n",
       " 'user_prompt': 'Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…\\n\\nØ£Ù†Ø§ ÙØªØ§Ø© Ø¨Ø¹Ù…Ø± 15 Ø³Ù†Ø©ØŒ Ø£Ø¹Ø§Ù†ÙŠ Ù…Ù† Ø£Ø­Ù„Ø§Ù… Ø§Ù„ÙŠÙ‚Ø¸Ø©ØŒ Ø±ØºÙ… ØªÙÙˆÙ‚ÙŠ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØŒ Ø¥Ù„Ø§ Ø£Ù†ÙŠ Ø£Ø­Ø³ Ø£Ù†ÙŠ Ø£Ø¹ÙŠØ´ ÙÙŠ Ø¹Ø§Ù„Ù… Ø¢Ø®Ø±ØŒ Ø­ÙŠØ« Ø£Ù†ÙŠ ÙØªØ§Ø© Ù…Ø­Ø¨ÙˆØ¨Ø© Ù…Ø´Ù‡ÙˆØ±Ø©ØŒ ÙˆØ§Ø«Ù‚Ø© ÙÙŠ Ù†ÙØ³Ù‡Ø§ØŒ ÙˆØªØ¯Ø±Ø³ Ø§Ù„Ù‡Ù†Ø¯Ø³Ø©ØŒ ÙˆÙƒÙ„ Ù…Ø±Ø© Ø£ØµÙ†Ø¹ Ù„Ù†ÙØ³ÙŠ (Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ) ÙˆØ£Ø¹ÙŠØ´ ÙÙŠÙ‡.\\n\\nÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ù‚ÙˆÙ„ Ø¨Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø°ÙŠ Ø§Ø®ØªØ±Ø¹ØªÙ‡ Ù„ÙŠ Ù‡Ùˆ Ø³Ø¨Ø¨ Ø³Ø¹Ø§Ø¯ØªÙŠØŒ Ù„ÙƒÙ†ÙŠ Ø£Ø­Ø³ Ø£Ù†ÙŠ Ù„Ù… Ø£Ø¹Ø¯ Ø£Ø³ØªÙ…ØªØ¹ Ø¨Ø¹Ø§Ù„Ù…ÙŠ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø¨Ù„ Ø£Ø±ÙŠØ¯ Ø£ÙŠ ÙØ±ØµØ© Ù„ÙƒÙŠ Ø£Ù‡Ø±Ø¨ Ø¥Ù„Ù‰ Ø¹Ø§Ù„Ù… Ø£Ø­Ù„Ø§Ù… Ø§Ù„ÙŠÙ‚Ø¸Ø©.\\n\\nØ£Ù†Ø§ Ø£Ø¹Ø§Ù†ÙŠ Ù…Ù† Ø§Ù„Ø®Ø¬Ù„ Ø§Ù„Ø´Ø¯ÙŠØ¯ØŒ ÙˆØ¹Ø¯Ù… Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„Ù†ÙØ³ Ø¹Ù†Ø¯Ù…Ø§ Ø£ÙƒÙˆÙ† ÙÙŠ Ø§Ù„Ø´Ø§Ø±Ø¹ Ø£Ùˆ Ø§Ù„Ù…Ø¯Ø±Ø³Ø© Ø£Ø­Ø³ Ø¨Ø£Ù† Ø§Ù„Ø¬Ù…ÙŠØ¹ ÙŠÙ†Ø¸Ø± Ø¥Ù„ÙŠØŒ ÙˆÙ‡Ø°Ø§ Ù…Ø§ ÙŠØ¬Ø¹Ù„Ù†ÙŠ Ø£ØªØµØ±Ù Ø¨ØºØ±Ø§Ø¨Ø©ØŒ ÙˆÙ…Ù† ÙƒØ«Ø±Ø© Ø®Ø¬Ù„ÙŠ Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø£Ù† Ø£Ø±ÙØ¹ Ø£ØµØ¨Ø¹ÙŠ ÙÙŠ Ø§Ù„Ù‚Ø³Ù….\\n\\nÙ‡Ø°Ø§ ÙŠØ³Ø¨Ø¨ Ù„ÙŠ Ù…Ø´ÙƒÙ„Ø© ÙƒØ¨ÙŠØ±Ø©ØŒ Ù„Ø§ Ø£Ø¹Ø±Ù Ù…Ø§ Ø³Ø¨Ø¨ Ø¹Ø¯Ù… Ø«Ù‚ØªÙŠ ÙÙŠ Ù†ÙØ³ÙŠØŸ! ÙØ£Ù†Ø§ ÙˆØ§Ø«Ù‚Ø© Ù…Ù† Ù‚Ø¯Ø±Ø§ØªÙŠØŒ ÙˆØ£Ø³ØªØ·ÙŠØ¹ Ø£Ù† Ø£Ø­Ù‚Ù‚ Ù…Ø§ Ø£Ø±ÙŠØ¯ØŒ Ù„ÙƒÙ† ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª Ù„Ø§ Ø£Ø´Ø¹Ø± Ø¨Ø§Ù„Ø±Ø§Ø­Ø© Ø¹Ù†Ø¯Ù…Ø§ Ø£ÙƒÙˆÙ† Ù…Ø¹ Ø£ÙŠ Ø£Ø­Ø¯ Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø£Ø¨ÙŠ ÙˆØ£Ù…ÙŠ ÙˆØ¥Ø®ÙˆØªÙŠ.\\n\\nÙ‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø± Ø£Ø¹Ø§Ù†ÙŠ Ù…Ù†Ù‡ Ù…Ù†Ø° Ø£Ø±Ø¨Ø¹ Ø³Ù†ÙˆØ§ØªØŒ ÙˆÙƒÙ„ Ù…Ø±Ø© Ø£Ù‚ÙˆÙ„ Ù„Ù†ÙØ³ÙŠ Ø³ÙŠØ£ØªÙŠ Ø§Ù„ÙˆÙ‚Øª ÙˆØªØªØ®Ù„ØµÙŠÙ† Ù…Ù†Ù‡ØŒ Ù„ÙƒÙ†ÙŠ Ø£Ø±Ù‰ Ø£Ù†Ù‡ Ø­Ø§Ù† Ø§Ù„ÙˆÙ‚Øª Ù„Ø£ØªØ¹Ø§Ù„Ø¬.\\n\\nØ£Ø±Ø¬ÙˆÙƒÙ… Ø³Ø§Ø¹Ø¯ÙˆÙ†ÙŠ.',\n",
       " 'cbt_technique': 'Ø§Ù„ØªØ¹Ø±Ø¶ Ø§Ù„ØªØ¯Ø±ÙŠØ¬ÙŠ ÙˆØ§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©',\n",
       " 'reason_for_technique': 'Ø§Ù„ØªØ¹Ø±Ø¶ Ø§Ù„ØªØ¯Ø±ÙŠØ¬ÙŠ ÙŠØ³Ø§Ø¹Ø¯ ÙÙŠ ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¬Ù„ Ù…Ù† Ø®Ù„Ø§Ù„ ØªØ¹Ø±ÙŠØ¶ Ø§Ù„Ù†ÙØ³ ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹ Ù„Ù„Ù…ÙˆØ§Ù‚Ù Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ© Ø§Ù„ØªÙŠ ØªØ³Ø¨Ø¨ Ø§Ù„Ù‚Ù„Ù‚. Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ© ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ¹Ø²Ø² Ø§Ù„Ø«Ù‚Ø© Ø¨Ø§Ù„Ù†ÙØ³ Ù…Ù† Ø®Ù„Ø§Ù„ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„Ø¢Ø®Ø±ÙŠÙ†.',\n",
       " 'cultural_context': 'ÙŠÙ…ÙƒÙ† ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø«Ù‚Ø© Ø¨Ø§Ù„Ù†ÙØ³ Ù…Ù† Ø®Ù„Ø§Ù„ Ø§Ù„ØªÙ…Ø³Ùƒ Ø¨Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ© Ù…Ø«Ù„ Ø§Ù„ØªÙˆÙƒÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ ÙˆØ§Ù„Ø±Ø¶Ø§ Ø¨Ø§Ù„Ù†ÙØ³. ÙƒÙ…Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ø¹Ø§Ø¦Ù„ÙŠ Ø§Ù„Ø°ÙŠ ÙŠØ¹ØªØ¨Ø± Ø¬Ø²Ø¡Ø§Ù‹ Ù…Ù‡Ù…Ø§Ù‹ Ù…Ù† Ø§Ù„Ø«Ù‚Ø§ÙØ© Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠØ©.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f653dd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:58:38,039 | INFO | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "out_prompt = await therapist_GPT.invoke_step2(out_prompt, session_id=\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a61f8a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÙˆØ¹Ù„ÙŠÙƒÙ… Ø§Ù„Ø³Ù„Ø§Ù… ÙˆØ±Ø­Ù…Ø© Ø§Ù„Ù„Ù‡ ÙˆØ¨Ø±ÙƒØ§ØªÙ‡ØŒ\n",
      "\n",
      "Ø£Ø®ØªÙŠ Ø§Ù„Ø¹Ø²ÙŠØ²Ø©ØŒ Ø£ÙˆÙ„Ø§Ù‹ Ø£ÙˆØ¯ Ø£Ù† Ø£Ù‡Ù†Ø¦Ùƒ Ø¹Ù„Ù‰ Ø´Ø¬Ø§Ø¹ØªÙƒ ÙÙŠ Ø§Ù„ØªØ¹Ø¨ÙŠØ± Ø¹Ù† Ù…Ø´Ø§Ø¹Ø±Ùƒ ÙˆØ§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©. Ù…Ù† Ø§Ù„ÙˆØ§Ø¶Ø­ Ø£Ù†Ùƒ ØªØ¹Ø§Ù†ÙŠÙ† Ù…Ù† Ø§Ù„Ø®Ø¬Ù„ ÙˆØ¹Ø¯Ù… Ø§Ù„Ø«Ù‚Ø© Ø¨Ø§Ù„Ù†ÙØ³ØŒ ÙˆÙ‡Ø°Ø§ Ø£Ù…Ø± Ø´Ø§Ø¦Ø¹ Ø¨ÙŠÙ† Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø´Ø¨Ø§Ø¨ ÙÙŠ Ù…Ø«Ù„ Ø¹Ù…Ø±Ùƒ.\n",
      "\n",
      "Ø£ÙˆØ¯ Ø£Ù† Ø£Ù‚ØªØ±Ø­ Ø¹Ù„ÙŠÙƒ ØªÙ‚Ù†ÙŠØ© Ø§Ù„Ø¹Ù„Ø§Ø¬ Ø§Ù„Ø³Ù„ÙˆÙƒÙŠ Ø§Ù„Ù…Ø¹Ø±ÙÙŠ Ø§Ù„ØªÙŠ ØªÙØ¹Ø±Ù Ø¨Ø§Ù„ØªØ¹Ø±Ø¶ Ø§Ù„ØªØ¯Ø±ÙŠØ¬ÙŠ ÙˆØ§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©. Ù‡Ø°Ù‡ Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙŠÙ…ÙƒÙ† Ø£Ù† ØªØ³Ø§Ø¹Ø¯Ùƒ ÙÙŠ Ø§Ù„ØªØºÙ„Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø¬Ù„ Ù…Ù† Ø®Ù„Ø§Ù„ ØªØ¹Ø±ÙŠØ¶ Ù†ÙØ³Ùƒ ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹ Ù„Ù„Ù…ÙˆØ§Ù‚Ù Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ© Ø§Ù„ØªÙŠ ØªØ³Ø¨Ø¨ Ù„Ùƒ Ø§Ù„Ù‚Ù„Ù‚ØŒ Ù…Ø«Ù„ Ø§Ù„ØªØ­Ø¯Ø« Ø£Ù…Ø§Ù… Ø²Ù…Ù„Ø§Ø¦Ùƒ ÙÙŠ Ø§Ù„Ù…Ø¯Ø±Ø³Ø© Ø£Ùˆ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ© ÙÙŠ Ø§Ù„Ø£Ù†Ø´Ø·Ø© Ø§Ù„Ø¬Ù…Ø§Ø¹ÙŠØ©. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¨Ø¯Ø¡ Ø¨Ø®Ø·ÙˆØ§Øª ØµØºÙŠØ±Ø©ØŒ Ù…Ø«Ù„ Ø±ÙØ¹ ÙŠØ¯Ùƒ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø¨Ø³ÙŠØ· ÙÙŠ Ø§Ù„ØµÙØŒ Ø«Ù… Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ§Øª ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹.\n",
      "\n",
      "Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø°Ù„ÙƒØŒ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ© ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ¹Ø²Ø² Ø«Ù‚ØªÙƒ Ø¨Ù†ÙØ³Ùƒ Ù…Ù† Ø®Ù„Ø§Ù„ ØªØ­Ø³ÙŠÙ† ØªÙØ§Ø¹Ù„Ùƒ Ù…Ø¹ Ø§Ù„Ø¢Ø®Ø±ÙŠÙ†. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¨Ø¯Ø¡ Ø¨Ø§Ù„ØªØ­Ø¯Ø« Ù…Ø¹ Ø£ØµØ¯Ù‚Ø§Ø¦Ùƒ Ø§Ù„Ù…Ù‚Ø±Ø¨ÙŠÙ† Ø£Ùˆ Ø£ÙØ±Ø§Ø¯ Ø¹Ø§Ø¦Ù„ØªÙƒ Ø¹Ù† Ù…Ø´Ø§Ø¹Ø±Ùƒ ÙˆØ£ÙÙƒØ§Ø±ÙƒØŒ Ø«Ù… ØªÙˆØ³ÙŠØ¹ Ø¯Ø§Ø¦Ø±Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹.\n",
      "\n",
      "Ù„Ø§ ØªÙ†Ø³ÙŠ Ø£Ù† Ø§Ù„ØªÙˆÙƒÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ ÙˆØ§Ù„Ø±Ø¶Ø§ Ø¨Ø§Ù„Ù†ÙØ³ Ù‡Ù…Ø§ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ© Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªØ¹Ø²Ø² Ø«Ù‚ØªÙƒ Ø¨Ù†ÙØ³Ùƒ. ÙƒÙ…Ø§ Ø£Ù† Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ø¹Ø§Ø¦Ù„ÙŠ Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹ØŒ Ù„Ø°Ø§ Ø­Ø§ÙˆÙ„ÙŠ Ø§Ù„ØªØ­Ø¯Ø« Ù…Ø¹ ÙˆØ§Ù„Ø¯ÙŠÙƒ Ø£Ùˆ Ø¥Ø®ÙˆØªÙƒ Ø¹Ù† Ù…Ø´Ø§Ø¹Ø±Ùƒ ÙˆØ·Ù„Ø¨ Ø¯Ø¹Ù…Ù‡Ù….\n",
      "\n",
      "Ø£ØªÙ…Ù†Ù‰ Ù„Ùƒ Ø§Ù„ØªÙˆÙÙŠÙ‚ ÙˆØ§Ù„Ù†Ø¬Ø§Ø­ ÙÙŠ Ø±Ø­Ù„ØªÙƒ Ù†Ø­Ùˆ ØªØ­Ø³ÙŠÙ† Ø«Ù‚ØªÙƒ Ø¨Ù†ÙØ³Ùƒ. Ø¥Ø°Ø§ ÙƒÙ†Øª Ø¨Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©ØŒ Ù„Ø§ ØªØªØ±Ø¯Ø¯ÙŠ ÙÙŠ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø´ÙˆØ±Ø© Ù…Ù† Ù…Ø®ØªØµ Ù†ÙØ³ÙŠ.\n"
     ]
    }
   ],
   "source": [
    "print(out_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
